{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InstalarSpark.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aD1ALMdAy6O"
      },
      "source": [
        "# PySpark en Google Colab\n",
        "\n",
        "Instalacion Octubre/2021\n",
        "\n",
        "1.   Instalacion Java\n",
        "2.   Instalacion de Spark\n",
        "3.   Instalar PySpark\n",
        "\n",
        "## De forma General para usar pyspark en Colab (2021) seria con los siguientes comandos en una celda en Colab:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JuWZdteAmvv"
      },
      "source": [
        "# instalar Java\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoApfKfpRunp"
      },
      "source": [
        "# Descargar la ultima versión de java ( comprobar que existen los path de descarga)\n",
        "#!wget -q https://archive.apache.org/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz # Download latest release. Update if necessary\n",
        "\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzHJ0bpuN-od",
        "outputId": "bd49732c-984b-426a-f606-365efb3f2c3c"
      },
      "source": [
        "%ls -la /content/\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 219204\n",
            "drwxr-xr-x 1 root root      4096 Sep 28 14:32 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 1 root root      4096 Sep 28 14:28 \u001b[01;34m..\u001b[0m/\n",
            "drwxr-xr-x 4 root root      4096 Sep 16 13:39 \u001b[01;34m.config\u001b[0m/\n",
            "drwxr-xr-x 1 root root      4096 Sep 16 13:40 \u001b[01;34msample_data\u001b[0m/\n",
            "-rw-r--r-- 1 root root 224445805 May 24 05:01 spark-3.1.2-bin-hadoop2.7.tgz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXpriDwJLP1I"
      },
      "source": [
        "!tar xf spark-3.1.2-bin-hadoop2.7.tgz"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Qih8Kt1MJla"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKlOUyKuMEr7",
        "outputId": "a98bf9b3-d3c6-44b6-edbc-bcc4efc965a7"
      },
      "source": [
        "# instalar pyspark\n",
        "!pip install -q pyspark"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 212.4 MB 61 kB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 49.6 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzkJ4JKkCgno"
      },
      "source": [
        "# Variables de entorno"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVEIOATyCYc6"
      },
      "source": [
        "import os # libreria de manejo del sistema operativo\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UCH8MwWGA-Q"
      },
      "source": [
        "# Cargar pyspark en el sistema"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38_3RcUSCiwb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "144667b5-0b99-45eb-c356-d347a891bf80"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "APP_NAME = \"PDGE-tutorialSpark1\"\n",
        "SPARK_URL = \"local[*]\"\n",
        "spark = SparkSession.builder.appName(APP_NAME).master(SPARK_URL).getOrCreate()\n",
        "spark"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://82d99ef4a924:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PDGE-tutorialSpark1</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f295f5ab510>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoAGmb4GY829",
        "outputId": "7bb24df6-b211-489d-c0c1-4489f17d51d6"
      },
      "source": [
        "sc = spark.sparkContext\n",
        "array = sc.parallelize([1,2,3,4,5,6,7,8,9,10], 2)\n",
        "array"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:274"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOLHf13HZ2h1",
        "outputId": "e24565a7-322f-4573-abde-7bbc08b60ef6"
      },
      "source": [
        "print(array.collect())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuZ5GDGqVwrS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb559071-a2bd-4ef3-a1ba-f6bd8a9b5982"
      },
      "source": [
        "print(array.count())\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    }
  ]
}