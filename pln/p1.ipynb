{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac1daa2f",
   "metadata": {},
   "source": [
    "<div style=\"font-weight: bold; color:#5D8AA8\" align=\"center\">\n",
    "    <div style=\"font-size: xx-large\">Procesamiento del Lenguaje Natural 2021-22</div><br>\n",
    "    <div style=\"font-size: x-large; color:gray\">Aspect opinion extraction</div><br>\n",
    "    <div style=\"font-size: large\">María Barroso - Gloria del Valle</div><br></div><hr>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c7b11c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bd9d3f",
   "metadata": {},
   "source": [
    "## Assignment 1: Review datasets\n",
    "\n",
    "**yelp_hotels.json**: json containing 5,034 reviews generated by 4,148 Yelp users about 284 hotels.\n",
    "\n",
    "**yelp_beauty_spas.json** and **yelp_restaurants.json**: which contain Yelp reviews about beauty/spa resorts and restaurants.\n",
    "\n",
    "Each review (JSON record) has the following fields:\n",
    "* *reviewerID*: the identifier of the user who wrote the review\n",
    "* *asin*: the identifier of the reviewed hotel\n",
    "* *reviewText*: the text of the user’s review about the hotel\n",
    "* *overall*: the 1-5 Likert scale rating assigned by the user to the hotel\n",
    "\n",
    "### Task 1.1\n",
    "Loading all the hotel reviews from the Yelp hotel reviews file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2f86c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp_hotels: 5034 reviews loaded\n"
     ]
    }
   ],
   "source": [
    "def load_all_json_yelp(data_name, data_path = 'yelp_dataset'):\n",
    "    with open(f'{data_path}/{data_name}.json', encoding='utf-8') as f:\n",
    "        reviews = json.load(f)\n",
    "    numReviews = len(reviews)\n",
    "    print(f'{data_name}: {numReviews} reviews loaded')\n",
    "    return reviews\n",
    "\n",
    "reviews_hotels = load_all_json_yelp('yelp_hotels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7477f01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reviewerID': 'qLCpuCWCyPb4G2vN-WZz-Q', 'asin': '8ZwO9VuLDWJOXmtAdc7LXQ', 'summary': 'summary', 'reviewText': \"Great hotel in Central Phoenix for a stay-cation, but not necessarily a place to stay out of town and without a car. Not much around the area, and unless you're familiar with downtown, I would rather have a guest stay in Old Town Scottsdale, etc. BUT if you do stay here, it's awesome. Great boutique rooms. Awesome pool that's happening in the summer. A GREAT rooftop patio bar, and a very very busy lobby with Gallo Blanco attached. A great place to stay, but have a car!\", 'overall': 4.0}\n",
      "qLCpuCWCyPb4G2vN-WZz-Q\n"
     ]
    }
   ],
   "source": [
    "print(reviews_hotels[0])\n",
    "print(reviews_hotels[0].get('reviewerID'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bac9ce5",
   "metadata": {},
   "source": [
    "### Task 1.2\n",
    "Loading line by line the reviews from the Yelp beauty/spa resorts and restaurants reviews files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "341b53f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_by_line_json_yelp(data_name, data_path = 'yelp_dataset'):\n",
    "    reviews = []\n",
    "    with open(f'{data_path}/{data_name}.json', encoding='utf-8') as f:\n",
    "        f.readline() # first line '['\n",
    "        numReviews = 0\n",
    "        while True:\n",
    "            numReviews += 1\n",
    "            line = f.readline().strip() # Get next line from file\n",
    "            if line == ']': # end of file is reached ']'\n",
    "                print(f'{data_name}: {numReviews} reviews loaded')\n",
    "                break\n",
    "            if line[-1] == ',':\n",
    "                line = line[:-1]\n",
    "            reviews.append(json.loads(line))\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08754abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp_beauty_spas: 5580 reviews loaded\n",
      "{'reviewerID': 'Xm8HXE1JHqscXe5BKf0GFQ', 'asin': 'WGNIYMeXPyoWav1APUq7jA', 'summary': 'summary', 'reviewText': \"Good tattoo shop. Clean space, multiple artists to choose from and books of their work are available for you to look though and decide who's style most mirrors what you're looking for. I chose Jet to do a cover-up for me and he worked with me on the design and our ideas and communication flowed very well. He's a very personable guy, is friendly and keeps the conversation going while he's working on you, and he doesn't dick around (read: He starts to work and continues until the job is done). He's very professional and informative. Good customer service combines with talent at the craft.\", 'overall': 4.0}\n",
      "Xm8HXE1JHqscXe5BKf0GFQ\n"
     ]
    }
   ],
   "source": [
    "reviews_spas = load_by_line_json_yelp('yelp_beauty_spas')\n",
    "print(reviews_spas[0])\n",
    "print(reviews_spas[0].get('reviewerID'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4c3d8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp_restaurants: 158431 reviews loaded\n",
      "{'reviewerID': 'rLtl8ZkDX5vH5nAx9C3q5Q', 'asin': '9yKzy9PApeiPPOUJEtnvkg', 'summary': 'summary', 'reviewText': 'My wife took me here on my birthday for breakfast and it was excellent. The weather was perfect which made sitting outside overlooking their grounds an absolute pleasure. Our waitress was excellent and our food arrived quickly on the semi-busy Saturday morning. It looked like the place fills up pretty quickly so the earlier you get here the better.Do yourself a favor and get their Bloody Mary. It was phenomenal and simply the best I\\'ve ever had. I\\'m pretty sure they only use ingredients from their garden and blend them fresh when you order it. It was amazing.While EVERYTHING on the menu looks excellent, I had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious. It came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete. It was the best \"toast\" I\\'ve ever had.Anyway, I can\\'t wait to go back!', 'overall': 5.0}\n",
      "rLtl8ZkDX5vH5nAx9C3q5Q\n"
     ]
    }
   ],
   "source": [
    "reviews_restaurants = load_by_line_json_yelp('yelp_restaurants')\n",
    "print(reviews_restaurants[0])\n",
    "print(reviews_restaurants[0].get('reviewerID'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09dc3f9",
   "metadata": {},
   "source": [
    "### Task 1.3\n",
    "Loading line by line* reviews on other domains like digital music from McAuley’s Amazon dataset2.\n",
    "\n",
    "Una opción de leer linea por linea un json muy grande es utilizar la función *read_json* de pandas con el atributo 'lines' a True. Después se ha realizado una limpieza del dataframe (eliminado columnas que no estuviesen en el dataset yelp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ced14212",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def read_by_line_json_amazon(data_name, data_path = 'amazon_dataset'):\n",
    "#    df = pd.read_json(f'{data_path}/{data_name}.json', lines=True)\n",
    "#    df.drop(inplace=True, columns=['verified', 'reviewTime', 'reviewerName', 'reviewText', 'unixReviewTime', 'style', 'image', 'vote'])\n",
    "#    return df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79fac904",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fashion_reviews = read_by_line_json_amazon('digital_music')\n",
    "#print(fashion_reviews[0])\n",
    "#print(fashion_reviews[0].get('reviewerID'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdeb3a7",
   "metadata": {},
   "source": [
    "## Assignment 2: Aspect vocabularies\n",
    "\n",
    "### Task 2.1\n",
    "Loading (and printing on screen) the vocabulary of the aspects_hotels.csv\n",
    "file, and directly using it to identify aspect references in the reviews. In particular, the aspects terms\n",
    "could be mapped by exact matching with nouns appearing in the reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dfa7609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_aspects(data_name, data_path = 'aspects'):\n",
    "    with open(f'{data_path}/{data_name}.csv', encoding='utf-8') as f:\n",
    "        aspects = {}\n",
    "        for line in f:\n",
    "            key, synonymous = line.rstrip('\\n').split(',')\n",
    "            if key in aspects and synonymous not in aspects[key]:\n",
    "                aspects[key].append(synonymous)\n",
    "            else:\n",
    "                aspects[key] = []\n",
    "    return aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de9add70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amenities': ['amenities', 'services'],\n",
       " 'atmosphere': ['atmospheres',\n",
       "  'ambiance',\n",
       "  'ambiances',\n",
       "  'light',\n",
       "  'lighting',\n",
       "  'lights',\n",
       "  'music'],\n",
       " 'bar': ['bars', 'bartender', 'bartenders'],\n",
       " 'bathrooms': ['bathrooms',\n",
       "  'bath',\n",
       "  'baths',\n",
       "  'bathtub',\n",
       "  'bathtubs',\n",
       "  'shampoo',\n",
       "  'shampoos',\n",
       "  'shower',\n",
       "  'showers',\n",
       "  'towel',\n",
       "  'towels',\n",
       "  'tub',\n",
       "  'tubs'],\n",
       " 'bedrooms': ['bedrooms',\n",
       "  'bed',\n",
       "  'beds',\n",
       "  'pillow',\n",
       "  'pillows',\n",
       "  'sheet',\n",
       "  'sheets',\n",
       "  'sleep',\n",
       "  'suite',\n",
       "  'suites'],\n",
       " 'booking': ['book', 'reservation', 'reservations', 'reserve'],\n",
       " 'breakfast': ['breakfasts',\n",
       "  'morning',\n",
       "  'mornings',\n",
       "  'toast',\n",
       "  'toasts',\n",
       "  'moorning meal',\n",
       "  'moorning menu'],\n",
       " 'building': ['decor',\n",
       "  'decoration',\n",
       "  'decorations',\n",
       "  'furniture',\n",
       "  'furnitures',\n",
       "  'garden',\n",
       "  'gardens',\n",
       "  'hall',\n",
       "  'halls',\n",
       "  'lobbies',\n",
       "  'lobby',\n",
       "  'lounge',\n",
       "  'lounges',\n",
       "  'patio',\n",
       "  'patios',\n",
       "  'salon',\n",
       "  'salons',\n",
       "  'spot',\n",
       "  'spots'],\n",
       " 'checking': ['check-in',\n",
       "  'check in',\n",
       "  'check ins',\n",
       "  'check out',\n",
       "  'check outs',\n",
       "  'checking',\n",
       "  'checkins',\n",
       "  'check-ins',\n",
       "  'checkout',\n",
       "  'check-out',\n",
       "  'checkouts',\n",
       "  'check-outs',\n",
       "  'check',\n",
       "  'checks',\n",
       "  'registration',\n",
       "  'registrations'],\n",
       " 'cleanliness': ['clean', 'cleaned', 'cleaning', 'dirt', 'dirty', 'smell'],\n",
       " 'coffee': ['coffees', 'cafe', 'cafes', 'tea', 'teas'],\n",
       " 'cuisine': ['cuisines',\n",
       "  'dishe',\n",
       "  'dishes',\n",
       "  'food',\n",
       "  'foods',\n",
       "  'meal',\n",
       "  'meals',\n",
       "  'menu',\n",
       "  'menus',\n",
       "  'plate',\n",
       "  'plates',\n",
       "  'buffet',\n",
       "  'buffets'],\n",
       " 'dinner': ['dinners',\n",
       "  'evening meal',\n",
       "  'evening menu',\n",
       "  'night meal',\n",
       "  'night menu'],\n",
       " 'drinks': ['drinks', 'beer', 'beers', 'wine', 'wines'],\n",
       " 'events': ['events',\n",
       "  'activity',\n",
       "  'activities',\n",
       "  'party',\n",
       "  'parties',\n",
       "  'trip',\n",
       "  'trips'],\n",
       " 'facilities': ['facility', 'equipment'],\n",
       " 'gym': ['gyms'],\n",
       " 'internet': ['wi fi', 'wifi', 'wi-fi', 'wireless'],\n",
       " 'location': ['locations',\n",
       "  'beach',\n",
       "  'beaches',\n",
       "  'environment',\n",
       "  'environments',\n",
       "  'lake',\n",
       "  'lakes',\n",
       "  'landscape',\n",
       "  'landscapes',\n",
       "  'mountain',\n",
       "  'mountains',\n",
       "  'neighborhood',\n",
       "  'neighborhoods',\n",
       "  'neighbourhood',\n",
       "  'neighbourhoods',\n",
       "  'river',\n",
       "  'rivers',\n",
       "  'situation',\n",
       "  'situations',\n",
       "  'street',\n",
       "  'streets',\n",
       "  'surrounding',\n",
       "  'surroundings',\n",
       "  'tree',\n",
       "  'trees',\n",
       "  'valley',\n",
       "  'valleys',\n",
       "  'view',\n",
       "  'views'],\n",
       " 'lunch': ['lunches',\n",
       "  'afternoon meal',\n",
       "  'afternoon menu',\n",
       "  'noon meal',\n",
       "  'noon menu'],\n",
       " 'parking': ['parkings'],\n",
       " 'pool': ['pools',\n",
       "  'swimming',\n",
       "  'swimming pool',\n",
       "  'swimming pools',\n",
       "  'swimmingpool',\n",
       "  'swimmingpools'],\n",
       " 'price': ['prices',\n",
       "  'priced',\n",
       "  'pricing',\n",
       "  'budget',\n",
       "  'budgets',\n",
       "  'charge',\n",
       "  'cost',\n",
       "  'costs',\n",
       "  'fee',\n",
       "  'fees',\n",
       "  'money'],\n",
       " 'restaurant': ['restaurants'],\n",
       " 'restrooms': ['restrooms', 'toilet', 'toilets'],\n",
       " 'service': ['serving',\n",
       "  'servings',\n",
       "  'attention',\n",
       "  'attentions',\n",
       "  'attitude',\n",
       "  'attitudes',\n",
       "  'server',\n",
       "  'servers'],\n",
       " 'shopping': ['shop',\n",
       "  'shops',\n",
       "  'store',\n",
       "  'stores',\n",
       "  'boutique',\n",
       "  'boutiques',\n",
       "  'mall',\n",
       "  'malls'],\n",
       " 'spa': ['spas', 'sauna', 'saunas', 'jacuzzi', 'jacuzzis'],\n",
       " 'staff': ['worker',\n",
       "  'workers',\n",
       "  'bellhop',\n",
       "  'bellhops',\n",
       "  'boss',\n",
       "  'bosses',\n",
       "  'cashier',\n",
       "  'employee',\n",
       "  'employees',\n",
       "  'hostess',\n",
       "  'manager',\n",
       "  'managers',\n",
       "  'owner',\n",
       "  'owners',\n",
       "  'patron',\n",
       "  'patrons',\n",
       "  'receptionist',\n",
       "  'receptionists'],\n",
       " 'temperature': ['temperatures'],\n",
       " 'transportation': ['transportation',\n",
       "  'transportations',\n",
       "  'bus',\n",
       "  'buses',\n",
       "  'cap',\n",
       "  'caps',\n",
       "  'car',\n",
       "  'cars',\n",
       "  'metro',\n",
       "  'metros',\n",
       "  'shuttle',\n",
       "  'shuttles',\n",
       "  'subway',\n",
       "  'subways',\n",
       "  'taxi',\n",
       "  'taxis',\n",
       "  'train',\n",
       "  'trains',\n",
       "  'tube',\n",
       "  'tubes',\n",
       "  'vehicle',\n",
       "  'vehicles']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspects_hotels = load_aspects('aspects_hotels')\n",
    "aspects_hotels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c40e26",
   "metadata": {},
   "source": [
    "### Task 2.2 \n",
    "\n",
    "Generating or extending the lists of terms of each aspect with synonyms extracted from WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cc10f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_aspects(aspects):\n",
    "    for key in aspects:\n",
    "        synsets = wn.synsets(key)\n",
    "        for synset in synsets:\n",
    "            lemmas = synset.lemma_names()\n",
    "            aspects[key] = list(set(aspects[key]  + lemmas))\n",
    "    return aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af5057f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amenities': ['agreeableness',\n",
       "  'amenities',\n",
       "  'amenity',\n",
       "  'comforts',\n",
       "  'conveniences',\n",
       "  'creature_comforts',\n",
       "  'services'],\n",
       " 'atmosphere': ['atmosphere',\n",
       "  'air',\n",
       "  'atmospheric_state',\n",
       "  'ambiance',\n",
       "  'aura',\n",
       "  'standard_pressure',\n",
       "  'music',\n",
       "  'light',\n",
       "  'atmospheres',\n",
       "  'ambiances',\n",
       "  'lights',\n",
       "  'standard_atmosphere',\n",
       "  'lighting',\n",
       "  'atm',\n",
       "  'ambience'],\n",
       " 'bar': ['legal_profession',\n",
       "  'block_off',\n",
       "  'stripe',\n",
       "  'bartender',\n",
       "  'saloon',\n",
       "  'bars',\n",
       "  'prevention',\n",
       "  'blockade',\n",
       "  'exclude',\n",
       "  'legal_community',\n",
       "  'measure',\n",
       "  'ginmill',\n",
       "  'cake',\n",
       "  'block_up',\n",
       "  'barricade',\n",
       "  'block',\n",
       "  'debar',\n",
       "  'bar',\n",
       "  'BAR',\n",
       "  'taproom',\n",
       "  'streak',\n",
       "  'stop',\n",
       "  'bartenders',\n",
       "  'banish',\n",
       "  'Browning_automatic_rifle',\n",
       "  'relegate',\n",
       "  'barroom'],\n",
       " 'bathrooms': ['shampoos',\n",
       "  'bathtub',\n",
       "  'towel',\n",
       "  'tubs',\n",
       "  'towels',\n",
       "  'showers',\n",
       "  'lavatory',\n",
       "  'bathroom',\n",
       "  'shampoo',\n",
       "  'tub',\n",
       "  'bathrooms',\n",
       "  'can',\n",
       "  'baths',\n",
       "  'lav',\n",
       "  'toilet',\n",
       "  'shower',\n",
       "  'john',\n",
       "  'bathtubs',\n",
       "  'bath',\n",
       "  'privy'],\n",
       " 'bedrooms': ['bed',\n",
       "  'bedchamber',\n",
       "  'suites',\n",
       "  'bedroom',\n",
       "  'sleeping_accommodation',\n",
       "  'sleep',\n",
       "  'bedrooms',\n",
       "  'chamber',\n",
       "  'pillows',\n",
       "  'pillow',\n",
       "  'sheet',\n",
       "  'sheets',\n",
       "  'sleeping_room',\n",
       "  'suite',\n",
       "  'beds'],\n",
       " 'booking': ['reservation',\n",
       "  'hold',\n",
       "  'reserve',\n",
       "  'booking',\n",
       "  'engagement',\n",
       "  'reservations',\n",
       "  'book'],\n",
       " 'breakfast': ['moorning meal',\n",
       "  'moorning menu',\n",
       "  'mornings',\n",
       "  'morning',\n",
       "  'toast',\n",
       "  'breakfasts',\n",
       "  'toasts',\n",
       "  'breakfast'],\n",
       " 'building': ['progress',\n",
       "  'establish',\n",
       "  'decoration',\n",
       "  'construct',\n",
       "  'gardens',\n",
       "  'build',\n",
       "  'salons',\n",
       "  'decorations',\n",
       "  'hall',\n",
       "  'work_up',\n",
       "  'ramp_up',\n",
       "  'decor',\n",
       "  'lobbies',\n",
       "  'lobby',\n",
       "  'lounge',\n",
       "  'edifice',\n",
       "  'salon',\n",
       "  'garden',\n",
       "  'build_up',\n",
       "  'furniture',\n",
       "  'spot',\n",
       "  'make',\n",
       "  'spots',\n",
       "  'furnitures',\n",
       "  'construction',\n",
       "  'halls',\n",
       "  'patio',\n",
       "  'building',\n",
       "  'lounges',\n",
       "  'patios'],\n",
       " 'checking': ['retard',\n",
       "  'check-in',\n",
       "  'agree',\n",
       "  'registrations',\n",
       "  'see_to_it',\n",
       "  'mark_off',\n",
       "  'check_up_on',\n",
       "  'check_out',\n",
       "  'correspond',\n",
       "  'check ins',\n",
       "  'tick_off',\n",
       "  'curb',\n",
       "  'jibe',\n",
       "  'check-out',\n",
       "  'check-ins',\n",
       "  'check-outs',\n",
       "  'determine',\n",
       "  'hold',\n",
       "  'checks',\n",
       "  'checker',\n",
       "  'chink',\n",
       "  'checkins',\n",
       "  'check',\n",
       "  'mark',\n",
       "  'chequer',\n",
       "  'insure',\n",
       "  'tick',\n",
       "  'watch',\n",
       "  'check_off',\n",
       "  'discipline',\n",
       "  'condition',\n",
       "  'control',\n",
       "  'tally',\n",
       "  'fit',\n",
       "  'hold_in',\n",
       "  'moderate',\n",
       "  'turn_back',\n",
       "  'match',\n",
       "  'hold_back',\n",
       "  'go_over',\n",
       "  'arrest',\n",
       "  'train',\n",
       "  'check out',\n",
       "  'check outs',\n",
       "  'find_out',\n",
       "  'crack',\n",
       "  'delay',\n",
       "  'suss_out',\n",
       "  'see',\n",
       "  'check in',\n",
       "  'registration',\n",
       "  'checkouts',\n",
       "  'checking',\n",
       "  'check_over',\n",
       "  'gibe',\n",
       "  'stop',\n",
       "  'ensure',\n",
       "  'checkout',\n",
       "  'check_into',\n",
       "  'ascertain',\n",
       "  'break',\n",
       "  'look_into',\n",
       "  'contain',\n",
       "  'learn',\n",
       "  'assure'],\n",
       " 'cleanliness': ['clean',\n",
       "  'cleaning',\n",
       "  'dirty',\n",
       "  'smell',\n",
       "  'cleanliness',\n",
       "  'cleaned',\n",
       "  'dirt'],\n",
       " 'coffee': ['coffees',\n",
       "  'java',\n",
       "  'burnt_umber',\n",
       "  'coffee_berry',\n",
       "  'coffee_tree',\n",
       "  'deep_brown',\n",
       "  'coffee_bean',\n",
       "  'cafe',\n",
       "  'cafes',\n",
       "  'umber',\n",
       "  'tea',\n",
       "  'teas',\n",
       "  'chocolate',\n",
       "  'coffee'],\n",
       " 'cuisine': ['menus',\n",
       "  'meal',\n",
       "  'meals',\n",
       "  'buffets',\n",
       "  'dishe',\n",
       "  'plates',\n",
       "  'food',\n",
       "  'buffet',\n",
       "  'menu',\n",
       "  'culinary_art',\n",
       "  'cuisines',\n",
       "  'dishes',\n",
       "  'foods',\n",
       "  'cuisine',\n",
       "  'plate'],\n",
       " 'dinner': ['evening menu',\n",
       "  'dinner',\n",
       "  'night meal',\n",
       "  'night menu',\n",
       "  'dinners',\n",
       "  'dinner_party',\n",
       "  'evening meal'],\n",
       " 'drinks': ['drinkable',\n",
       "  'wassail',\n",
       "  'toast',\n",
       "  'drink',\n",
       "  'wines',\n",
       "  'beverage',\n",
       "  'boozing',\n",
       "  'crapulence',\n",
       "  'imbibe',\n",
       "  'drink_in',\n",
       "  'salute',\n",
       "  'potable',\n",
       "  'drinks',\n",
       "  'swallow',\n",
       "  'deglutition',\n",
       "  'fuddle',\n",
       "  'booze',\n",
       "  'drinking',\n",
       "  'beers',\n",
       "  'wine',\n",
       "  'drunkenness',\n",
       "  'tope',\n",
       "  'beer',\n",
       "  'pledge'],\n",
       " 'events': ['outcome',\n",
       "  'effect',\n",
       "  'upshot',\n",
       "  'events',\n",
       "  'activity',\n",
       "  'issue',\n",
       "  'party',\n",
       "  'trips',\n",
       "  'case',\n",
       "  'activities',\n",
       "  'consequence',\n",
       "  'event',\n",
       "  'trip',\n",
       "  'result',\n",
       "  'parties'],\n",
       " 'facilities': ['quickness',\n",
       "  'adroitness',\n",
       "  'facility',\n",
       "  'equipment',\n",
       "  'adeptness',\n",
       "  'deftness',\n",
       "  'readiness',\n",
       "  'installation'],\n",
       " 'gym': ['gyms', 'gymnasium', 'gym'],\n",
       " 'internet': ['wi fi',\n",
       "  'wireless',\n",
       "  'net',\n",
       "  'cyberspace',\n",
       "  'wi-fi',\n",
       "  'internet',\n",
       "  'wifi'],\n",
       " 'location': ['tree',\n",
       "  'location',\n",
       "  'emplacement',\n",
       "  'locating',\n",
       "  'streets',\n",
       "  'lake',\n",
       "  'rivers',\n",
       "  'trees',\n",
       "  'situation',\n",
       "  'mountain',\n",
       "  'landscape',\n",
       "  'street',\n",
       "  'situations',\n",
       "  'locations',\n",
       "  'environment',\n",
       "  'lakes',\n",
       "  'landscapes',\n",
       "  'valley',\n",
       "  'valleys',\n",
       "  'neighbourhood',\n",
       "  'neighborhood',\n",
       "  'position',\n",
       "  'beaches',\n",
       "  'river',\n",
       "  'localisation',\n",
       "  'neighborhoods',\n",
       "  'fix',\n",
       "  'positioning',\n",
       "  'neighbourhoods',\n",
       "  'mountains',\n",
       "  'view',\n",
       "  'environments',\n",
       "  'views',\n",
       "  'surrounding',\n",
       "  'placement',\n",
       "  'surroundings',\n",
       "  'localization',\n",
       "  'beach'],\n",
       " 'lunch': ['lunch',\n",
       "  'tiffin',\n",
       "  'noon meal',\n",
       "  'noon menu',\n",
       "  'lunches',\n",
       "  'afternoon menu',\n",
       "  'afternoon meal',\n",
       "  'luncheon',\n",
       "  'dejeuner'],\n",
       " 'parking': ['park', 'parkings', 'parking'],\n",
       " 'pool': ['puddle',\n",
       "  'swimmingpools',\n",
       "  'pool',\n",
       "  'swimming pools',\n",
       "  'kitty',\n",
       "  'pools',\n",
       "  'swimming pool',\n",
       "  'consortium',\n",
       "  'swimmingpool',\n",
       "  'pond',\n",
       "  'pocket_billiards',\n",
       "  'syndicate',\n",
       "  'swimming'],\n",
       " 'price': ['cost',\n",
       "  'prices',\n",
       "  'Price',\n",
       "  'terms',\n",
       "  'price',\n",
       "  'damage',\n",
       "  'budget',\n",
       "  'monetary_value',\n",
       "  'priced',\n",
       "  'costs',\n",
       "  'toll',\n",
       "  'charge',\n",
       "  'fee',\n",
       "  'Leontyne_Price',\n",
       "  'money',\n",
       "  'pricing',\n",
       "  'fees',\n",
       "  'budgets',\n",
       "  'Mary_Leontyne_Price'],\n",
       " 'restaurant': ['eating_place',\n",
       "  'restaurants',\n",
       "  'eating_house',\n",
       "  'restaurant',\n",
       "  'eatery'],\n",
       " 'restrooms': ['toilet_facility',\n",
       "  'convenience',\n",
       "  'wash_room',\n",
       "  'public_lavatory',\n",
       "  'public_toilet',\n",
       "  'restrooms',\n",
       "  'toilet',\n",
       "  'toilets',\n",
       "  'comfort_station',\n",
       "  'restroom',\n",
       "  'public_convenience'],\n",
       " 'service': ['military_service',\n",
       "  'table_service',\n",
       "  'service',\n",
       "  'serving',\n",
       "  'service_of_process',\n",
       "  'overhaul',\n",
       "  'divine_service',\n",
       "  'religious_service',\n",
       "  'servings',\n",
       "  'inspection_and_repair',\n",
       "  'avail',\n",
       "  'help',\n",
       "  'serve',\n",
       "  'attitude',\n",
       "  'servers',\n",
       "  'server',\n",
       "  'attitudes',\n",
       "  'servicing',\n",
       "  'attention',\n",
       "  'armed_service',\n",
       "  'Service',\n",
       "  'Robert_William_Service',\n",
       "  'attentions'],\n",
       " 'shopping': ['snitch',\n",
       "  'betray',\n",
       "  'shopping',\n",
       "  'mall',\n",
       "  'store',\n",
       "  'shit',\n",
       "  'stores',\n",
       "  'sponsor',\n",
       "  'shop',\n",
       "  'boutiques',\n",
       "  'patronize',\n",
       "  'boutique',\n",
       "  'shop_at',\n",
       "  'frequent',\n",
       "  'browse',\n",
       "  'buy_at',\n",
       "  'tell_on',\n",
       "  'rat',\n",
       "  'stag',\n",
       "  'give_away',\n",
       "  'grass',\n",
       "  'denounce',\n",
       "  'malls',\n",
       "  'shops',\n",
       "  'patronise'],\n",
       " 'spa': ['spas',\n",
       "  'spa',\n",
       "  'sauna',\n",
       "  'health_club',\n",
       "  'health_spa',\n",
       "  'jacuzzis',\n",
       "  'watering_hole',\n",
       "  'watering_place',\n",
       "  'saunas',\n",
       "  'resort_hotel',\n",
       "  'jacuzzi'],\n",
       " 'staff': ['boss',\n",
       "  'staff',\n",
       "  'owners',\n",
       "  'employee',\n",
       "  'patrons',\n",
       "  'manager',\n",
       "  'workers',\n",
       "  'bosses',\n",
       "  'employees',\n",
       "  'managers',\n",
       "  'bellhops',\n",
       "  'hostess',\n",
       "  'owner',\n",
       "  'worker',\n",
       "  'bellhop',\n",
       "  'cashier',\n",
       "  'receptionist',\n",
       "  'receptionists',\n",
       "  'patron',\n",
       "  'stave',\n",
       "  'faculty'],\n",
       " 'temperature': ['temperature', 'temperatures'],\n",
       " 'transportation': ['cap',\n",
       "  'tube',\n",
       "  'shuttle',\n",
       "  'shuttles',\n",
       "  'expatriation',\n",
       "  'taxi',\n",
       "  'deportation',\n",
       "  'metros',\n",
       "  'Transportation',\n",
       "  'bus',\n",
       "  'transportation_system',\n",
       "  'transit',\n",
       "  'fare',\n",
       "  'conveyance',\n",
       "  'transfer',\n",
       "  'subways',\n",
       "  'subway',\n",
       "  'transferral',\n",
       "  'car',\n",
       "  'DoT',\n",
       "  'cars',\n",
       "  'taxis',\n",
       "  'trains',\n",
       "  'buses',\n",
       "  'transportation',\n",
       "  'train',\n",
       "  'tubes',\n",
       "  'vehicle',\n",
       "  'Department_of_Transportation',\n",
       "  'vehicles',\n",
       "  'transport',\n",
       "  'metro',\n",
       "  'caps',\n",
       "  'transportations',\n",
       "  'shipping',\n",
       "  'exile']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspects_hotels = extend_aspects(aspects_hotels)\n",
    "aspects_hotels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25915195",
   "metadata": {},
   "source": [
    "### Task 2.3 \n",
    "Managing vocabularies for additional Yelp or Amazon domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a971ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amenities': ['agreeableness',\n",
       "  'amenities',\n",
       "  'amenity',\n",
       "  'comforts',\n",
       "  'conveniences',\n",
       "  'creature_comforts',\n",
       "  'services'],\n",
       " 'atmosphere': ['atmosphere',\n",
       "  'air',\n",
       "  'atmospheric_state',\n",
       "  'ambiance',\n",
       "  'aura',\n",
       "  'standard_pressure',\n",
       "  'music',\n",
       "  'light',\n",
       "  'atmospheres',\n",
       "  'ambiances',\n",
       "  'lights',\n",
       "  'standard_atmosphere',\n",
       "  'lighting',\n",
       "  'atm',\n",
       "  'ambiences',\n",
       "  'ambience'],\n",
       " 'bar': ['legal_profession',\n",
       "  'block_off',\n",
       "  'stripe',\n",
       "  'bartender',\n",
       "  'saloon',\n",
       "  'bars',\n",
       "  'prevention',\n",
       "  'blockade',\n",
       "  'exclude',\n",
       "  'legal_community',\n",
       "  'measure',\n",
       "  'ginmill',\n",
       "  'cake',\n",
       "  'block_up',\n",
       "  'barricade',\n",
       "  'block',\n",
       "  'debar',\n",
       "  'bar',\n",
       "  'BAR',\n",
       "  'taproom',\n",
       "  'streak',\n",
       "  'stop',\n",
       "  'bartenders',\n",
       "  'banish',\n",
       "  'Browning_automatic_rifle',\n",
       "  'relegate',\n",
       "  'barroom'],\n",
       " 'bathrooms': ['shampoos',\n",
       "  'bathtub',\n",
       "  'towel',\n",
       "  'tubs',\n",
       "  'towels',\n",
       "  'showers',\n",
       "  'lavatory',\n",
       "  'bathroom',\n",
       "  'shampoo',\n",
       "  'tub',\n",
       "  'bathrooms',\n",
       "  'can',\n",
       "  'baths',\n",
       "  'lav',\n",
       "  'toilet',\n",
       "  'shower',\n",
       "  'john',\n",
       "  'bathtubs',\n",
       "  'bath',\n",
       "  'privy'],\n",
       " 'bedrooms': ['bed',\n",
       "  'bedchamber',\n",
       "  'suites',\n",
       "  'bedroom',\n",
       "  'sleeping_accommodation',\n",
       "  'sleep',\n",
       "  'bedrooms',\n",
       "  'chamber',\n",
       "  'pillows',\n",
       "  'pillow',\n",
       "  'sheet',\n",
       "  'sheets',\n",
       "  'sleeping_room',\n",
       "  'suite',\n",
       "  'beds'],\n",
       " 'booking': ['reservation',\n",
       "  'hold',\n",
       "  'reserve',\n",
       "  'booking',\n",
       "  'engagement',\n",
       "  'reservations',\n",
       "  'book'],\n",
       " 'breakfast': ['moorning meal',\n",
       "  'moorning menu',\n",
       "  'mornings',\n",
       "  'morning',\n",
       "  'toast',\n",
       "  'breakfasts',\n",
       "  'toasts',\n",
       "  'breakfast'],\n",
       " 'building': ['progress',\n",
       "  'establish',\n",
       "  'decoration',\n",
       "  'construct',\n",
       "  'gardens',\n",
       "  'build',\n",
       "  'salons',\n",
       "  'decorations',\n",
       "  'hall',\n",
       "  'work_up',\n",
       "  'ramp_up',\n",
       "  'decor',\n",
       "  'lobbies',\n",
       "  'lobby',\n",
       "  'lounge',\n",
       "  'edifice',\n",
       "  'salon',\n",
       "  'garden',\n",
       "  'build_up',\n",
       "  'furniture',\n",
       "  'spot',\n",
       "  'make',\n",
       "  'spots',\n",
       "  'furnitures',\n",
       "  'construction',\n",
       "  'halls',\n",
       "  'patio',\n",
       "  'building',\n",
       "  'lounges',\n",
       "  'patios'],\n",
       " 'checking': ['retard',\n",
       "  'check-in',\n",
       "  'agree',\n",
       "  'registrations',\n",
       "  'see_to_it',\n",
       "  'mark_off',\n",
       "  'check_up_on',\n",
       "  'check_out',\n",
       "  'correspond',\n",
       "  'check ins',\n",
       "  'tick_off',\n",
       "  'curb',\n",
       "  'jibe',\n",
       "  'check-out',\n",
       "  'check-ins',\n",
       "  'check-outs',\n",
       "  'determine',\n",
       "  'hold',\n",
       "  'checks',\n",
       "  'checker',\n",
       "  'chink',\n",
       "  'checkins',\n",
       "  'check',\n",
       "  'mark',\n",
       "  'chequer',\n",
       "  'insure',\n",
       "  'tick',\n",
       "  'watch',\n",
       "  'check_off',\n",
       "  'discipline',\n",
       "  'condition',\n",
       "  'control',\n",
       "  'tally',\n",
       "  'fit',\n",
       "  'hold_in',\n",
       "  'moderate',\n",
       "  'turn_back',\n",
       "  'match',\n",
       "  'hold_back',\n",
       "  'go_over',\n",
       "  'arrest',\n",
       "  'train',\n",
       "  'check out',\n",
       "  'check outs',\n",
       "  'find_out',\n",
       "  'crack',\n",
       "  'delay',\n",
       "  'suss_out',\n",
       "  'see',\n",
       "  'check in',\n",
       "  'registration',\n",
       "  'checkouts',\n",
       "  'checking',\n",
       "  'check_over',\n",
       "  'gibe',\n",
       "  'stop',\n",
       "  'ensure',\n",
       "  'checkout',\n",
       "  'check_into',\n",
       "  'ascertain',\n",
       "  'break',\n",
       "  'look_into',\n",
       "  'contain',\n",
       "  'learn',\n",
       "  'assure'],\n",
       " 'cleanliness': ['clean',\n",
       "  'cleaning',\n",
       "  'dirty',\n",
       "  'smell',\n",
       "  'cleanliness',\n",
       "  'cleaned',\n",
       "  'dirt'],\n",
       " 'coffee': ['coffees',\n",
       "  'java',\n",
       "  'burnt_umber',\n",
       "  'coffee_berry',\n",
       "  'coffee_tree',\n",
       "  'deep_brown',\n",
       "  'coffee_bean',\n",
       "  'cafe',\n",
       "  'cafes',\n",
       "  'umber',\n",
       "  'tea',\n",
       "  'teas',\n",
       "  'chocolate',\n",
       "  'coffee'],\n",
       " 'cuisine': ['menus',\n",
       "  'meal',\n",
       "  'meals',\n",
       "  'buffets',\n",
       "  'dishe',\n",
       "  'plates',\n",
       "  'food',\n",
       "  'buffet',\n",
       "  'menu',\n",
       "  'culinary_art',\n",
       "  'cuisines',\n",
       "  'dishes',\n",
       "  'foods',\n",
       "  'cuisine',\n",
       "  'plate'],\n",
       " 'dinner': ['evening menu',\n",
       "  'dinner',\n",
       "  'night meal',\n",
       "  'night menu',\n",
       "  'dinners',\n",
       "  'dinner_party',\n",
       "  'evening meal'],\n",
       " 'drinks': ['drinkable',\n",
       "  'wassail',\n",
       "  'toast',\n",
       "  'drink',\n",
       "  'wines',\n",
       "  'beverage',\n",
       "  'boozing',\n",
       "  'crapulence',\n",
       "  'imbibe',\n",
       "  'drink_in',\n",
       "  'salute',\n",
       "  'potable',\n",
       "  'drinks',\n",
       "  'swallow',\n",
       "  'deglutition',\n",
       "  'fuddle',\n",
       "  'booze',\n",
       "  'drinking',\n",
       "  'beers',\n",
       "  'wine',\n",
       "  'drunkenness',\n",
       "  'tope',\n",
       "  'beer',\n",
       "  'pledge'],\n",
       " 'events': ['outcome',\n",
       "  'effect',\n",
       "  'upshot',\n",
       "  'events',\n",
       "  'activity',\n",
       "  'issue',\n",
       "  'party',\n",
       "  'trips',\n",
       "  'case',\n",
       "  'activities',\n",
       "  'consequence',\n",
       "  'event',\n",
       "  'trip',\n",
       "  'result',\n",
       "  'parties'],\n",
       " 'face': ['fount',\n",
       "  'case',\n",
       "  'boldness',\n",
       "  'brow',\n",
       "  'grimace',\n",
       "  'human_face',\n",
       "  'face_up',\n",
       "  'present',\n",
       "  'faces',\n",
       "  'facial_expression',\n",
       "  'facial',\n",
       "  'front',\n",
       "  'eyebrow',\n",
       "  'side',\n",
       "  'facials',\n",
       "  'look',\n",
       "  'makeup',\n",
       "  'cheek',\n",
       "  'aspect',\n",
       "  'font',\n",
       "  'confront',\n",
       "  'face',\n",
       "  'typeface',\n",
       "  'nerve',\n",
       "  'eyebrows',\n",
       "  'brass',\n",
       "  'expression'],\n",
       " 'facilities': ['quickness',\n",
       "  'adroitness',\n",
       "  'facility',\n",
       "  'equipment',\n",
       "  'adeptness',\n",
       "  'deftness',\n",
       "  'readiness',\n",
       "  'installation'],\n",
       " 'gym': ['gyms', 'gymnasium', 'gym'],\n",
       " 'hair': ['haircut',\n",
       "  'whisker',\n",
       "  'hair',\n",
       "  'hairsbreadth',\n",
       "  'hairs',\n",
       "  'barbers',\n",
       "  'pilus',\n",
       "  'tomentum',\n",
       "  'fuzz',\n",
       "  'barber',\n",
       "  'haircloth',\n",
       "  \"hair's-breadth\"],\n",
       " 'internet': ['wi fi',\n",
       "  'wireless',\n",
       "  'net',\n",
       "  'cyberspace',\n",
       "  'wi-fi',\n",
       "  'internet',\n",
       "  'wifi'],\n",
       " 'location': ['tree',\n",
       "  'location',\n",
       "  'emplacement',\n",
       "  'locating',\n",
       "  'streets',\n",
       "  'lake',\n",
       "  'rivers',\n",
       "  'trees',\n",
       "  'situation',\n",
       "  'mountain',\n",
       "  'landscape',\n",
       "  'street',\n",
       "  'situations',\n",
       "  'locations',\n",
       "  'environment',\n",
       "  'lakes',\n",
       "  'landscapes',\n",
       "  'valley',\n",
       "  'valleys',\n",
       "  'neighbourhood',\n",
       "  'neighborhood',\n",
       "  'position',\n",
       "  'beaches',\n",
       "  'river',\n",
       "  'localisation',\n",
       "  'neighborhoods',\n",
       "  'fix',\n",
       "  'positioning',\n",
       "  'neighbourhoods',\n",
       "  'mountains',\n",
       "  'view',\n",
       "  'environments',\n",
       "  'views',\n",
       "  'surrounding',\n",
       "  'placement',\n",
       "  'surroundings',\n",
       "  'localization',\n",
       "  'beach'],\n",
       " 'lunch': ['lunch',\n",
       "  'tiffin',\n",
       "  'noon meal',\n",
       "  'noon menu',\n",
       "  'lunches',\n",
       "  'afternoon menu',\n",
       "  'afternoon meal',\n",
       "  'luncheon',\n",
       "  'dejeuner'],\n",
       " 'manicure': ['manicure', 'mani', 'manicures', 'hands', 'hand'],\n",
       " 'massages': ['rest',\n",
       "  'massages',\n",
       "  'relaxing',\n",
       "  'rub_down',\n",
       "  'massage',\n",
       "  'relaxation',\n",
       "  'relaxed',\n",
       "  'knead'],\n",
       " 'nails': ['nail',\n",
       "  'nail_down',\n",
       "  'complete',\n",
       "  'pick_up',\n",
       "  'ace',\n",
       "  'apprehend',\n",
       "  'boom',\n",
       "  'cop',\n",
       "  'sail_through',\n",
       "  'nab',\n",
       "  'collar',\n",
       "  'blast',\n",
       "  'arrest',\n",
       "  'peg',\n",
       "  'sweep_through',\n",
       "  'pass_with_flying_colors',\n",
       "  'smash',\n",
       "  'pinpoint',\n",
       "  'nails',\n",
       "  'breeze_through'],\n",
       " 'parking': ['park', 'parkings', 'parking'],\n",
       " 'pedicure': ['pedicures', 'toe', 'toes', 'pedicure', 'pedi', 'foot'],\n",
       " 'pool': ['puddle',\n",
       "  'swimmingpools',\n",
       "  'pool',\n",
       "  'swimming pools',\n",
       "  'kitty',\n",
       "  'pools',\n",
       "  'swimming pool',\n",
       "  'consortium',\n",
       "  'swimmingpool',\n",
       "  'pond',\n",
       "  'pocket_billiards',\n",
       "  'syndicate',\n",
       "  'swimming'],\n",
       " 'price': ['cost',\n",
       "  'prices',\n",
       "  'Price',\n",
       "  'terms',\n",
       "  'price',\n",
       "  'damage',\n",
       "  'budget',\n",
       "  'monetary_value',\n",
       "  'priced',\n",
       "  'costs',\n",
       "  'toll',\n",
       "  'charge',\n",
       "  'fee',\n",
       "  'Leontyne_Price',\n",
       "  'money',\n",
       "  'pricing',\n",
       "  'fees',\n",
       "  'budgets',\n",
       "  'Mary_Leontyne_Price'],\n",
       " 'products': ['waxing',\n",
       "  'ware',\n",
       "  'Cartesian_product',\n",
       "  'production',\n",
       "  'product',\n",
       "  'gel',\n",
       "  'merchandise',\n",
       "  'soap',\n",
       "  'products',\n",
       "  'gels',\n",
       "  'soaps',\n",
       "  'lotions',\n",
       "  'mathematical_product',\n",
       "  'lotion',\n",
       "  'wax',\n",
       "  'intersection'],\n",
       " 'restaurant': ['eating_place',\n",
       "  'restaurants',\n",
       "  'eating_house',\n",
       "  'restaurant',\n",
       "  'eatery'],\n",
       " 'restrooms': ['toilet_facility',\n",
       "  'convenience',\n",
       "  'wash_room',\n",
       "  'public_lavatory',\n",
       "  'public_toilet',\n",
       "  'restrooms',\n",
       "  'toilet',\n",
       "  'toilets',\n",
       "  'comfort_station',\n",
       "  'restroom',\n",
       "  'public_convenience'],\n",
       " 'service': ['military_service',\n",
       "  'table_service',\n",
       "  'service',\n",
       "  'serving',\n",
       "  'service_of_process',\n",
       "  'overhaul',\n",
       "  'divine_service',\n",
       "  'religious_service',\n",
       "  'servings',\n",
       "  'inspection_and_repair',\n",
       "  'avail',\n",
       "  'help',\n",
       "  'serve',\n",
       "  'attitude',\n",
       "  'servers',\n",
       "  'server',\n",
       "  'attitudes',\n",
       "  'servicing',\n",
       "  'attention',\n",
       "  'armed_service',\n",
       "  'Service',\n",
       "  'Robert_William_Service',\n",
       "  'attentions'],\n",
       " 'shopping': ['snitch',\n",
       "  'betray',\n",
       "  'shopping',\n",
       "  'mall',\n",
       "  'store',\n",
       "  'shit',\n",
       "  'stores',\n",
       "  'sponsor',\n",
       "  'shop',\n",
       "  'boutiques',\n",
       "  'patronize',\n",
       "  'boutique',\n",
       "  'shop_at',\n",
       "  'frequent',\n",
       "  'browse',\n",
       "  'buy_at',\n",
       "  'tell_on',\n",
       "  'rat',\n",
       "  'stag',\n",
       "  'give_away',\n",
       "  'grass',\n",
       "  'denounce',\n",
       "  'malls',\n",
       "  'shops',\n",
       "  'patronise'],\n",
       " 'skin': ['bark',\n",
       "  'tegument',\n",
       "  'skin',\n",
       "  'scrape',\n",
       "  'skins',\n",
       "  'scramble',\n",
       "  'pare',\n",
       "  'peel',\n",
       "  'struggle',\n",
       "  'cutis',\n",
       "  'sputter',\n",
       "  'pelt',\n",
       "  'shinny',\n",
       "  'clamber',\n",
       "  'shin',\n",
       "  'hide'],\n",
       " 'spa': ['spas',\n",
       "  'spa',\n",
       "  'sauna',\n",
       "  'health_club',\n",
       "  'health_spa',\n",
       "  'jacuzzis',\n",
       "  'watering_hole',\n",
       "  'watering_place',\n",
       "  'saunas',\n",
       "  'resort_hotel',\n",
       "  'jacuzzi'],\n",
       " 'staff': ['boss',\n",
       "  'staff',\n",
       "  'owners',\n",
       "  'employee',\n",
       "  'patrons',\n",
       "  'manager',\n",
       "  'workers',\n",
       "  'bosses',\n",
       "  'employees',\n",
       "  'managers',\n",
       "  'bellhops',\n",
       "  'hostess',\n",
       "  'owner',\n",
       "  'worker',\n",
       "  'bellhop',\n",
       "  'cashier',\n",
       "  'receptionist',\n",
       "  'receptionists',\n",
       "  'patron',\n",
       "  'stave',\n",
       "  'faculty'],\n",
       " 'temperature': ['temperature', 'temperatures'],\n",
       " 'transportation': ['cap',\n",
       "  'tube',\n",
       "  'shuttle',\n",
       "  'shuttles',\n",
       "  'expatriation',\n",
       "  'taxi',\n",
       "  'deportation',\n",
       "  'metros',\n",
       "  'Transportation',\n",
       "  'bus',\n",
       "  'transportation_system',\n",
       "  'transit',\n",
       "  'fare',\n",
       "  'conveyance',\n",
       "  'transfer',\n",
       "  'subways',\n",
       "  'subway',\n",
       "  'transferral',\n",
       "  'car',\n",
       "  'DoT',\n",
       "  'cars',\n",
       "  'taxis',\n",
       "  'trains',\n",
       "  'buses',\n",
       "  'transportation',\n",
       "  'train',\n",
       "  'tubes',\n",
       "  'vehicle',\n",
       "  'Department_of_Transportation',\n",
       "  'vehicles',\n",
       "  'transport',\n",
       "  'metro',\n",
       "  'caps',\n",
       "  'transportations',\n",
       "  'shipping',\n",
       "  'exile'],\n",
       " 'treatments': ['handling',\n",
       "  'care',\n",
       "  'discourse',\n",
       "  'treatment',\n",
       "  'intervention',\n",
       "  'treatments',\n",
       "  'cares',\n",
       "  'discussion']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspects_spas = load_aspects('aspects_spas')\n",
    "aspects_spas = extend_aspects(aspects_spas)\n",
    "aspects_spas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19c829eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'appetizers': ['starter',\n",
       "  'starters',\n",
       "  'appetiser',\n",
       "  'entrees',\n",
       "  'appetizer',\n",
       "  'appetizers',\n",
       "  'entree'],\n",
       " 'asian': ['noodle',\n",
       "  'noodles',\n",
       "  'curries',\n",
       "  'curry',\n",
       "  'Asiatic',\n",
       "  'Asian',\n",
       "  'sushies',\n",
       "  'sushi'],\n",
       " 'atmosphere': ['atmosphere',\n",
       "  'air',\n",
       "  'atmospheric_state',\n",
       "  'ambiance',\n",
       "  'aura',\n",
       "  'standard_pressure',\n",
       "  'music',\n",
       "  'light',\n",
       "  'atmospheres',\n",
       "  'ambiances',\n",
       "  'lights',\n",
       "  'standard_atmosphere',\n",
       "  'lighting',\n",
       "  'atm',\n",
       "  'ambience'],\n",
       " 'bar': ['legal_profession',\n",
       "  'block_off',\n",
       "  'stripe',\n",
       "  'bartender',\n",
       "  'saloon',\n",
       "  'bars',\n",
       "  'prevention',\n",
       "  'blockade',\n",
       "  'exclude',\n",
       "  'legal_community',\n",
       "  'measure',\n",
       "  'ginmill',\n",
       "  'cake',\n",
       "  'block_up',\n",
       "  'barricade',\n",
       "  'block',\n",
       "  'debar',\n",
       "  'bar',\n",
       "  'BAR',\n",
       "  'taproom',\n",
       "  'streak',\n",
       "  'stop',\n",
       "  'bartenders',\n",
       "  'banish',\n",
       "  'Browning_automatic_rifle',\n",
       "  'relegate',\n",
       "  'barroom'],\n",
       " 'booking': ['reservation',\n",
       "  'hold',\n",
       "  'reserve',\n",
       "  'booking',\n",
       "  'engagement',\n",
       "  'reservations',\n",
       "  'book'],\n",
       " 'bread': ['staff_of_life',\n",
       "  'gelt',\n",
       "  'scratch',\n",
       "  'breadstuff',\n",
       "  'clams',\n",
       "  'bread',\n",
       "  'lucre',\n",
       "  'pelf',\n",
       "  'simoleons',\n",
       "  'boodle',\n",
       "  'dough',\n",
       "  'dinero',\n",
       "  'loot',\n",
       "  'wampum',\n",
       "  'sugar',\n",
       "  'breads',\n",
       "  'cabbage',\n",
       "  'kale',\n",
       "  'lettuce',\n",
       "  'roll',\n",
       "  'shekels',\n",
       "  'rolls',\n",
       "  'moolah',\n",
       "  'lolly'],\n",
       " 'breakfast': ['moorning meal',\n",
       "  'moorning menu',\n",
       "  'mornings',\n",
       "  'morning',\n",
       "  'toast',\n",
       "  'breakfasts',\n",
       "  'toasts',\n",
       "  'breakfast'],\n",
       " 'building': ['progress',\n",
       "  'establish',\n",
       "  'decoration',\n",
       "  'construct',\n",
       "  'gardens',\n",
       "  'build',\n",
       "  'salons',\n",
       "  'decorations',\n",
       "  'hall',\n",
       "  'work_up',\n",
       "  'ramp_up',\n",
       "  'decor',\n",
       "  'lobbies',\n",
       "  'lobby',\n",
       "  'lounge',\n",
       "  'edifice',\n",
       "  'salon',\n",
       "  'garden',\n",
       "  'build_up',\n",
       "  'furniture',\n",
       "  'spot',\n",
       "  'make',\n",
       "  'spots',\n",
       "  'furnitures',\n",
       "  'construction',\n",
       "  'halls',\n",
       "  'patio',\n",
       "  'building',\n",
       "  'lounges',\n",
       "  'patios'],\n",
       " 'cheese': ['high_mallow',\n",
       "  'Malva_sylvestris',\n",
       "  'cheeses',\n",
       "  'cheese',\n",
       "  'cheeseflower',\n",
       "  'tall_mallow'],\n",
       " 'cleanliness': ['clean',\n",
       "  'cleaning',\n",
       "  'dirty',\n",
       "  'smell',\n",
       "  'cleanliness',\n",
       "  'cleaned',\n",
       "  'dirt'],\n",
       " 'coffee': ['coffees',\n",
       "  'java',\n",
       "  'burnt_umber',\n",
       "  'coffee_berry',\n",
       "  'coffee_tree',\n",
       "  'deep_brown',\n",
       "  'coffee_bean',\n",
       "  'cafe',\n",
       "  'cafes',\n",
       "  'umber',\n",
       "  'tea',\n",
       "  'teas',\n",
       "  'chocolate',\n",
       "  'coffee'],\n",
       " 'desserts': ['crusts',\n",
       "  'dessert',\n",
       "  'crust',\n",
       "  'pie',\n",
       "  'pies',\n",
       "  'cakes',\n",
       "  'cake',\n",
       "  'chocolates',\n",
       "  'sweet',\n",
       "  'afters',\n",
       "  'desserts',\n",
       "  'chocolate'],\n",
       " 'dinner': ['evening menu',\n",
       "  'dinner',\n",
       "  'night meal',\n",
       "  'night menu',\n",
       "  'dinners',\n",
       "  'dinner_party',\n",
       "  'evening meal'],\n",
       " 'drinks': ['drinkable',\n",
       "  'wassail',\n",
       "  'toast',\n",
       "  'drink',\n",
       "  'wines',\n",
       "  'beverage',\n",
       "  'boozing',\n",
       "  'crapulence',\n",
       "  'imbibe',\n",
       "  'drink_in',\n",
       "  'salute',\n",
       "  'potable',\n",
       "  'drinks',\n",
       "  'swallow',\n",
       "  'deglutition',\n",
       "  'fuddle',\n",
       "  'booze',\n",
       "  'drinking',\n",
       "  'beers',\n",
       "  'wine',\n",
       "  'drunkenness',\n",
       "  'tope',\n",
       "  'beer',\n",
       "  'pledge'],\n",
       " 'eggs': ['eggs',\n",
       "  'egg',\n",
       "  'testicle',\n",
       "  'orchis',\n",
       "  'testis',\n",
       "  'ball',\n",
       "  'ballock',\n",
       "  'bollock',\n",
       "  'nut'],\n",
       " 'food': ['food quality',\n",
       "  'quality',\n",
       "  'food_for_thought',\n",
       "  'intellectual_nourishment',\n",
       "  'solid_food',\n",
       "  'nutrient',\n",
       "  'qualities',\n",
       "  'ingredients',\n",
       "  'food',\n",
       "  'ingredient',\n",
       "  'foods',\n",
       "  'food qualities'],\n",
       " 'food_quantity': ['food quantities', 'portion', 'portions'],\n",
       " 'food_taste': ['tastes',\n",
       "  'tasted',\n",
       "  'flavor',\n",
       "  'flavorful',\n",
       "  'flavoring',\n",
       "  'flavors',\n",
       "  'flavours'],\n",
       " 'hamburgers': ['hamburgers',\n",
       "  'sandwiches',\n",
       "  'sandwich',\n",
       "  'beefburger',\n",
       "  'burgers',\n",
       "  'burger',\n",
       "  'ground_beef',\n",
       "  'hamburger'],\n",
       " 'italian': ['pastas', 'Italian', 'pasta', 'pizza', 'pizzas'],\n",
       " 'location': ['tree',\n",
       "  'location',\n",
       "  'emplacement',\n",
       "  'locating',\n",
       "  'streets',\n",
       "  'lake',\n",
       "  'rivers',\n",
       "  'trees',\n",
       "  'situation',\n",
       "  'mountain',\n",
       "  'landscape',\n",
       "  'street',\n",
       "  'situations',\n",
       "  'locations',\n",
       "  'environment',\n",
       "  'lakes',\n",
       "  'landscapes',\n",
       "  'valley',\n",
       "  'valleys',\n",
       "  'neighbourhood',\n",
       "  'neighborhood',\n",
       "  'position',\n",
       "  'beaches',\n",
       "  'river',\n",
       "  'localisation',\n",
       "  'neighborhoods',\n",
       "  'fix',\n",
       "  'positioning',\n",
       "  'neighbourhoods',\n",
       "  'mountains',\n",
       "  'view',\n",
       "  'environments',\n",
       "  'views',\n",
       "  'surrounding',\n",
       "  'placement',\n",
       "  'surroundings',\n",
       "  'localization',\n",
       "  'beach'],\n",
       " 'lunch': ['lunch',\n",
       "  'tiffin',\n",
       "  'noon meal',\n",
       "  'noon menu',\n",
       "  'lunches',\n",
       "  'afternoon menu',\n",
       "  'afternoon meal',\n",
       "  'luncheon',\n",
       "  'dejeuner'],\n",
       " 'meat': ['wings',\n",
       "  'chickens',\n",
       "  'kernel',\n",
       "  'centre',\n",
       "  'ribs',\n",
       "  'heart_and_soul',\n",
       "  'pork',\n",
       "  'heart',\n",
       "  'nub',\n",
       "  'wing',\n",
       "  'inwardness',\n",
       "  'meats',\n",
       "  'substance',\n",
       "  'steaks',\n",
       "  'sum',\n",
       "  'chicken',\n",
       "  'porks',\n",
       "  'core',\n",
       "  'marrow',\n",
       "  'beef',\n",
       "  'meat',\n",
       "  'center',\n",
       "  'nitty-gritty',\n",
       "  'gist',\n",
       "  'pith',\n",
       "  'essence',\n",
       "  'beefs',\n",
       "  'steak',\n",
       "  'rib   '],\n",
       " 'menu': ['card',\n",
       "  'variety',\n",
       "  'bill_of_fare',\n",
       "  'plate',\n",
       "  'menus',\n",
       "  'meal',\n",
       "  'fare',\n",
       "  'meals',\n",
       "  'buffets',\n",
       "  'carte',\n",
       "  'cuisines',\n",
       "  'carte_du_jour',\n",
       "  'buffet',\n",
       "  'varieties',\n",
       "  'menu',\n",
       "  'dish',\n",
       "  'computer_menu',\n",
       "  'plates',\n",
       "  'dishes'],\n",
       " 'mexican': ['nacho',\n",
       "  'burrito',\n",
       "  'Mexican',\n",
       "  'taco',\n",
       "  'chilis',\n",
       "  'burritos',\n",
       "  'chili',\n",
       "  'nachos',\n",
       "  'tacos'],\n",
       " 'parking': ['park', 'parkings', 'parking'],\n",
       " 'potatoes': ['spud',\n",
       "  'chips',\n",
       "  'white_potato',\n",
       "  'potato',\n",
       "  'murphy',\n",
       "  'white_potato_vine',\n",
       "  'frie',\n",
       "  'Solanum_tuberosum',\n",
       "  'fries',\n",
       "  'tater',\n",
       "  'Irish_potato',\n",
       "  'potatoes',\n",
       "  'chip'],\n",
       " 'price': ['cost',\n",
       "  'prices',\n",
       "  'Price',\n",
       "  'terms',\n",
       "  'price',\n",
       "  'damage',\n",
       "  'budget',\n",
       "  'monetary_value',\n",
       "  'priced',\n",
       "  'costs',\n",
       "  'toll',\n",
       "  'charge',\n",
       "  'fee',\n",
       "  'Leontyne_Price',\n",
       "  'money',\n",
       "  'pricing',\n",
       "  'fees',\n",
       "  'budgets',\n",
       "  'Mary_Leontyne_Price'],\n",
       " 'restrooms': ['toilet_facility',\n",
       "  'convenience',\n",
       "  'wash_room',\n",
       "  'public_lavatory',\n",
       "  'public_toilet',\n",
       "  'restrooms',\n",
       "  'toilet',\n",
       "  'toilets',\n",
       "  'comfort_station',\n",
       "  'restroom',\n",
       "  'bathrooms',\n",
       "  'public_convenience'],\n",
       " 'rice': ['Sir_Tim_Rice',\n",
       "  'Elmer_Leopold_Rice',\n",
       "  'Elmer_Reizenstein',\n",
       "  'rices',\n",
       "  'Rice',\n",
       "  'Elmer_Rice',\n",
       "  'rice',\n",
       "  'Timothy_Miles_Bindon_Rice'],\n",
       " 'sauces': ['sauces', 'sauce', 'salsas'],\n",
       " 'seafood': ['fishes',\n",
       "  'seafoods',\n",
       "  'fish',\n",
       "  'cod',\n",
       "  'shrimps',\n",
       "  'seafood',\n",
       "  'salmons',\n",
       "  'cods',\n",
       "  'shrimp',\n",
       "  'salmon'],\n",
       " 'seating': ['couch',\n",
       "  'chair',\n",
       "  'sit',\n",
       "  'sitting',\n",
       "  'seating',\n",
       "  'seating_room',\n",
       "  'tables',\n",
       "  'comforts',\n",
       "  'sit_down',\n",
       "  'comfort',\n",
       "  'seating_area',\n",
       "  'induct',\n",
       "  'table',\n",
       "  'couches',\n",
       "  'seat',\n",
       "  'seats',\n",
       "  'invest',\n",
       "  'chairs'],\n",
       " 'service': ['military_service',\n",
       "  'table_service',\n",
       "  'service',\n",
       "  'serving',\n",
       "  'service_of_process',\n",
       "  'overhaul',\n",
       "  'divine_service',\n",
       "  'religious_service',\n",
       "  'servings',\n",
       "  'inspection_and_repair',\n",
       "  'avail',\n",
       "  'help',\n",
       "  'serve',\n",
       "  'attitude',\n",
       "  'servers',\n",
       "  'server',\n",
       "  'attitudes',\n",
       "  'servicing',\n",
       "  'attention',\n",
       "  'armed_service',\n",
       "  'Service',\n",
       "  'Robert_William_Service',\n",
       "  'attentions'],\n",
       " 'shopping': ['snitch',\n",
       "  'betray',\n",
       "  'shopping',\n",
       "  'mall',\n",
       "  'store',\n",
       "  'shit',\n",
       "  'stores',\n",
       "  'sponsor',\n",
       "  'shop',\n",
       "  'boutiques',\n",
       "  'patronize',\n",
       "  'boutique',\n",
       "  'shop_at',\n",
       "  'frequent',\n",
       "  'browse',\n",
       "  'buy_at',\n",
       "  'tell_on',\n",
       "  'rat',\n",
       "  'stag',\n",
       "  'give_away',\n",
       "  'grass',\n",
       "  'denounce',\n",
       "  'malls',\n",
       "  'shops',\n",
       "  'patronise'],\n",
       " 'soups': ['soups', 'soup'],\n",
       " 'staff': ['waitress',\n",
       "  'chef',\n",
       "  'boss',\n",
       "  'staff',\n",
       "  'waitresses',\n",
       "  'owners',\n",
       "  'employee',\n",
       "  'patrons',\n",
       "  'chefs',\n",
       "  'manager',\n",
       "  'workers',\n",
       "  'waiter',\n",
       "  'bosses',\n",
       "  'employees',\n",
       "  'managers',\n",
       "  'waitstaff',\n",
       "  'hostess',\n",
       "  'owner',\n",
       "  'worker',\n",
       "  'cashier',\n",
       "  'waiters',\n",
       "  'patron',\n",
       "  'stave',\n",
       "  'faculty'],\n",
       " 'temperature': ['temperature', 'temperatures'],\n",
       " 'transportation': ['cap',\n",
       "  'tube',\n",
       "  'shuttle',\n",
       "  'shuttles',\n",
       "  'expatriation',\n",
       "  'taxi',\n",
       "  'deportation',\n",
       "  'metros',\n",
       "  'Transportation',\n",
       "  'bus',\n",
       "  'transportation_system',\n",
       "  'transit',\n",
       "  'fare',\n",
       "  'conveyance',\n",
       "  'transfer',\n",
       "  'subways',\n",
       "  'subway',\n",
       "  'transferral',\n",
       "  'car',\n",
       "  'DoT',\n",
       "  'cars',\n",
       "  'taxis',\n",
       "  'trains',\n",
       "  'buses',\n",
       "  'transportation',\n",
       "  'train',\n",
       "  'tubes',\n",
       "  'vehicle',\n",
       "  'Department_of_Transportation',\n",
       "  'vehicles',\n",
       "  'transport',\n",
       "  'metro',\n",
       "  'caps',\n",
       "  'transportations',\n",
       "  'shipping',\n",
       "  'exile'],\n",
       " 'vegetables': ['veggie',\n",
       "  'vegetables',\n",
       "  'peppers',\n",
       "  'bean',\n",
       "  'beans',\n",
       "  'onion',\n",
       "  'onions',\n",
       "  'corns',\n",
       "  'salads',\n",
       "  'vegetable',\n",
       "  'pepper',\n",
       "  'tomato',\n",
       "  'salad',\n",
       "  'corn',\n",
       "  'veg',\n",
       "  'tomatoes']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspects_restaurants = load_aspects('aspects_restaurants')\n",
    "aspects_restaurants = extend_aspects(aspects_restaurants)\n",
    "aspects_restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963c63fc",
   "metadata": {},
   "source": [
    "### Task 2.4\n",
    "Identifying hidden/implicit aspect references in reviews. For instance, the example review of page 1 has references to the hotel’s location and transportation aspects, since there is “not much around the area” and \"going by car to the hotel is recommendable\".\n",
    "\n",
    "\n",
    "For this task, we are going to considerer the hyponym of words. For example, that 'area' is a hyponym of 'location'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c40a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e05d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11e1fdaf",
   "metadata": {},
   "source": [
    "## Assignment 3: Opinion Lexicon\n",
    "\n",
    "### Task 3.1\n",
    "\n",
    "Loading Liu’s opinion lexicon composed of positive and negative words, accessible as an NLKT corpus, and exploiting it to assign the polarity values to aspect opinions in assignment 4. Instead of this lexicon, you are allowed to use others, such as SentiWordNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "433e6c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('opinion_lexicon')\n",
    "from nltk.corpus import opinion_lexicon\n",
    "\n",
    "negativeWords = opinion_lexicon.negative()\n",
    "positiveWords = opinion_lexicon.positive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d11324f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('sentiwordnet')\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "def penn_to_wn(tag):\n",
    "    \"\"\"\n",
    "    Convert between the PennTreebank tags to simple Wordnet tags\n",
    "    \"\"\"\n",
    "    if tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    elif tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    return None\n",
    "\n",
    "def get_sentiment(sentence):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    token = nltk.word_tokenize(sentence)\n",
    "    after_tagging = nltk.pos_tag(token)\n",
    "    sentiment = 0\n",
    "    for word, tag in after_tagging:\n",
    "\n",
    "        wn_tag = penn_to_wn(tag)\n",
    "        if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV):\n",
    "            continue\n",
    "\n",
    "        lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
    "        if not lemma:\n",
    "            continue\n",
    "\n",
    "        synsets = wn.synsets(lemma, pos=wn_tag)\n",
    "        if not synsets:\n",
    "            continue\n",
    "\n",
    "        # Take the first sense, the most common\n",
    "        synset = synsets[0]\n",
    "        swn_synset = swn.senti_synset(synset.name())\n",
    "\n",
    "        sentiment += swn_synset.pos_score() - swn_synset.neg_score()\n",
    "    return sentiment\n",
    "\n",
    "get_sentiment('it is not a funny joke')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eccdf688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.vader import VaderConstants\n",
    "\n",
    "def get_vader_score(sent):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    # Polarity score returns dictionary\n",
    "    ss = sid.polarity_scores(sent)\n",
    "    #return ss\n",
    "    idx = np.argmax(list(ss.values())[:-1])\n",
    "    if idx==0: return -1.0\n",
    "    if idx==1: return 0.0\n",
    "    if idx==2: return 1.0\n",
    "\n",
    "get_vader_score('it is not a funny joke')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc68d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcea3bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 11:03:29.238611: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-29 11:03:29.238639: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "#!python -m spacy download en_core_web_lg\n",
    "file = nltk.data.load(\"vader_lexicon/vader_lexicon.txt\")\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbf16db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lexicon2 between -3, 3\n",
    "lexicon = {}\n",
    "# $:\t-1.5\t0.80623\t[-1, -1, -1, -1, -3, -1, -3, -1, -2, -1]\n",
    "for l in file.split(\"\\n\"):\n",
    "    word, polarity = l.strip().split(\"\\t\")[0:2]\n",
    "    lexicon[word] = float(polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0585686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$:': -1.5,\n",
       " '%)': -0.4,\n",
       " '%-)': -1.5,\n",
       " '&-:': -0.4,\n",
       " '&:': -0.7,\n",
       " \"( '}{' )\": 1.6,\n",
       " '(%': -0.9,\n",
       " \"('-:\": 2.2,\n",
       " \"(':\": 2.3,\n",
       " '((-:': 2.1,\n",
       " '(*': 1.1,\n",
       " '(-%': -0.7,\n",
       " '(-*': 1.3,\n",
       " '(-:': 1.6,\n",
       " '(-:0': 2.8,\n",
       " '(-:<': -0.4,\n",
       " '(-:o': 1.5,\n",
       " '(-:O': 1.5,\n",
       " '(-:{': -0.1,\n",
       " '(-:|>*': 1.9,\n",
       " '(-;': 1.3,\n",
       " '(-;|': 2.1,\n",
       " '(8': 2.6,\n",
       " '(:': 2.2,\n",
       " '(:0': 2.4,\n",
       " '(:<': -0.2,\n",
       " '(:o': 2.5,\n",
       " '(:O': 2.5,\n",
       " '(;': 1.1,\n",
       " '(;<': 0.3,\n",
       " '(=': 2.2,\n",
       " '(?:': 2.1,\n",
       " '(^:': 1.5,\n",
       " '(^;': 1.5,\n",
       " '(^;0': 2.0,\n",
       " '(^;o': 1.9,\n",
       " '(o:': 1.6,\n",
       " \")':\": -2.0,\n",
       " \")-':\": -2.1,\n",
       " ')-:': -2.1,\n",
       " ')-:<': -2.2,\n",
       " ')-:{': -2.1,\n",
       " '):': -1.8,\n",
       " '):<': -1.9,\n",
       " '):{': -2.3,\n",
       " ');<': -2.6,\n",
       " '*)': 0.6,\n",
       " '*-)': 0.3,\n",
       " '*-:': 2.1,\n",
       " '*-;': 2.4,\n",
       " '*:': 1.9,\n",
       " '*<|:-)': 1.6,\n",
       " '*\\\\0/*': 2.3,\n",
       " '*^:': 1.6,\n",
       " ',-:': 1.2,\n",
       " \"---'-;-{@\": 2.3,\n",
       " '--<--<@': 2.2,\n",
       " '.-:': -1.2,\n",
       " '..###-:': -1.7,\n",
       " '..###:': -1.9,\n",
       " '/-:': -1.3,\n",
       " '/:': -1.3,\n",
       " '/:<': -1.4,\n",
       " '/=': -0.9,\n",
       " '/^:': -1.0,\n",
       " '/o:': -1.4,\n",
       " '0-8': 0.1,\n",
       " '0-|': -1.2,\n",
       " '0:)': 1.9,\n",
       " '0:-)': 1.4,\n",
       " '0:-3': 1.5,\n",
       " '0:03': 1.9,\n",
       " '0;^)': 1.6,\n",
       " '0_o': -0.3,\n",
       " '10q': 2.1,\n",
       " '1337': 2.1,\n",
       " '143': 3.2,\n",
       " '1432': 2.6,\n",
       " '14aa41': 2.4,\n",
       " '182': -2.9,\n",
       " '187': -3.1,\n",
       " '2g2b4g': 2.8,\n",
       " '2g2bt': -0.1,\n",
       " '2qt': 2.1,\n",
       " '3:(': -2.2,\n",
       " '3:)': 0.5,\n",
       " '3:-(': -2.3,\n",
       " '3:-)': -1.4,\n",
       " '4col': -2.2,\n",
       " '4q': -3.1,\n",
       " '5fs': 1.5,\n",
       " '8)': 1.9,\n",
       " '8-d': 1.7,\n",
       " '8-o': -0.3,\n",
       " '86': -1.6,\n",
       " '8d': 2.9,\n",
       " ':###..': -2.4,\n",
       " ':$': -0.2,\n",
       " ':&': -0.6,\n",
       " \":'(\": -2.2,\n",
       " \":')\": 2.3,\n",
       " \":'-(\": -2.4,\n",
       " \":'-)\": 2.7,\n",
       " ':(': -1.9,\n",
       " ':)': 2.0,\n",
       " ':*': 2.5,\n",
       " ':-###..': -2.5,\n",
       " ':-&': -0.5,\n",
       " ':-(': -1.5,\n",
       " ':-)': 1.3,\n",
       " ':-))': 2.8,\n",
       " ':-*': 1.7,\n",
       " ':-,': 1.1,\n",
       " ':-.': -0.9,\n",
       " ':-/': -1.2,\n",
       " ':-<': -1.5,\n",
       " ':-d': 2.3,\n",
       " ':-D': 2.3,\n",
       " ':-o': 0.1,\n",
       " ':-p': 1.5,\n",
       " ':-[': -1.6,\n",
       " ':-\\\\': -0.9,\n",
       " ':-c': -1.3,\n",
       " ':-|': -0.7,\n",
       " ':-||': -2.5,\n",
       " ':-Þ': 0.9,\n",
       " ':/': -1.4,\n",
       " ':3': 2.3,\n",
       " ':<': -2.1,\n",
       " ':>': 2.1,\n",
       " ':?)': 1.3,\n",
       " ':?c': -1.6,\n",
       " ':@': -2.5,\n",
       " ':d': 2.3,\n",
       " ':D': 2.3,\n",
       " ':l': -1.7,\n",
       " ':o': -0.4,\n",
       " ':p': 1.4,\n",
       " ':s': -1.2,\n",
       " ':[': -2.0,\n",
       " ':\\\\': -1.3,\n",
       " ':]': 2.2,\n",
       " ':^)': 2.1,\n",
       " ':^*': 2.6,\n",
       " ':^/': -1.2,\n",
       " ':^\\\\': -1.0,\n",
       " ':^|': -1.0,\n",
       " ':c': -2.1,\n",
       " ':c)': 2.0,\n",
       " ':o)': 2.1,\n",
       " ':o/': -1.4,\n",
       " ':o\\\\': -1.1,\n",
       " ':o|': -0.6,\n",
       " ':{': -1.9,\n",
       " ':|': -0.4,\n",
       " ':}': 2.1,\n",
       " ':Þ': 1.1,\n",
       " ';)': 0.9,\n",
       " ';-)': 1.0,\n",
       " ';-*': 2.2,\n",
       " ';-]': 0.7,\n",
       " ';d': 0.8,\n",
       " ';D': 0.8,\n",
       " ';]': 0.6,\n",
       " ';^)': 1.4,\n",
       " '</3': -3.0,\n",
       " '<3': 1.9,\n",
       " '<:': 2.1,\n",
       " '<:-|': -1.4,\n",
       " '=)': 2.2,\n",
       " '=-3': 2.0,\n",
       " '=-d': 2.4,\n",
       " '=-D': 2.4,\n",
       " '=/': -1.4,\n",
       " '=3': 2.1,\n",
       " '=d': 2.3,\n",
       " '=D': 2.3,\n",
       " '=l': -1.2,\n",
       " '=\\\\': -1.2,\n",
       " '=]': 1.6,\n",
       " '=p': 1.3,\n",
       " '=|': -0.8,\n",
       " '>-:': -2.0,\n",
       " '>.<': -1.3,\n",
       " '>:': -2.1,\n",
       " '>:(': -2.7,\n",
       " '>:)': 0.4,\n",
       " '>:-(': -2.7,\n",
       " '>:-)': -0.4,\n",
       " '>:/': -1.6,\n",
       " '>:o': -1.2,\n",
       " '>:p': 1.0,\n",
       " '>:[': -2.1,\n",
       " '>:\\\\': -1.7,\n",
       " '>;(': -2.9,\n",
       " '>;)': 0.1,\n",
       " '>_>^': 2.1,\n",
       " '@:': -2.1,\n",
       " '@>-->--': 2.1,\n",
       " \"@}-;-'---\": 2.2,\n",
       " 'aas': 2.5,\n",
       " 'aayf': 2.7,\n",
       " 'afu': -2.9,\n",
       " 'alol': 2.8,\n",
       " 'ambw': 2.9,\n",
       " 'aml': 3.4,\n",
       " 'atab': -1.9,\n",
       " 'awol': -1.3,\n",
       " 'ayc': 0.2,\n",
       " 'ayor': -1.2,\n",
       " 'aug-00': 0.3,\n",
       " 'bfd': -2.7,\n",
       " 'bfe': -2.6,\n",
       " 'bff': 2.9,\n",
       " 'bffn': 1.0,\n",
       " 'bl': 2.3,\n",
       " 'bsod': -2.2,\n",
       " 'btd': -2.1,\n",
       " 'btdt': -0.1,\n",
       " 'bz': 0.4,\n",
       " 'b^d': 2.6,\n",
       " 'cwot': -2.3,\n",
       " \"d-':\": -2.5,\n",
       " 'd8': -3.2,\n",
       " 'd:': 1.2,\n",
       " 'd:<': -3.2,\n",
       " 'd;': -2.9,\n",
       " 'd=': 1.5,\n",
       " 'doa': -2.3,\n",
       " 'dx': -3.0,\n",
       " 'ez': 1.5,\n",
       " 'fav': 2.0,\n",
       " 'fcol': -1.8,\n",
       " 'ff': 1.8,\n",
       " 'ffs': -2.8,\n",
       " 'fkm': -2.4,\n",
       " 'foaf': 1.8,\n",
       " 'ftw': 2.0,\n",
       " 'fu': -3.7,\n",
       " 'fubar': -3.0,\n",
       " 'fwb': 2.5,\n",
       " 'fyi': 0.8,\n",
       " 'fysa': 0.4,\n",
       " 'g1': 1.4,\n",
       " 'gg': 1.2,\n",
       " 'gga': 1.7,\n",
       " 'gigo': -0.6,\n",
       " 'gj': 2.0,\n",
       " 'gl': 1.3,\n",
       " 'gla': 2.5,\n",
       " 'gn': 1.2,\n",
       " 'gr8': 2.7,\n",
       " 'grrr': -0.4,\n",
       " 'gt': 1.1,\n",
       " 'h&k': 2.3,\n",
       " 'hagd': 2.2,\n",
       " 'hagn': 2.2,\n",
       " 'hago': 1.2,\n",
       " 'hak': 1.9,\n",
       " 'hand': 2.2,\n",
       " 'hho1/2k': 1.4,\n",
       " 'hhoj': 2.0,\n",
       " 'hhok': 0.9,\n",
       " 'hugz': 2.0,\n",
       " 'hi5': 1.9,\n",
       " 'idk': -0.4,\n",
       " 'ijs': 0.7,\n",
       " 'ilu': 3.4,\n",
       " 'iluaaf': 2.7,\n",
       " 'ily': 3.4,\n",
       " 'ily2': 2.6,\n",
       " 'iou': 0.7,\n",
       " 'iyq': 2.3,\n",
       " 'j/j': 2.0,\n",
       " 'j/k': 1.6,\n",
       " 'j/p': 1.4,\n",
       " 'j/t': -0.2,\n",
       " 'j/w': 1.0,\n",
       " 'j4f': 1.4,\n",
       " 'j4g': 1.7,\n",
       " 'jho': 0.8,\n",
       " 'jhomf': 1.0,\n",
       " 'jj': 1.0,\n",
       " 'jk': 0.9,\n",
       " 'jp': 0.8,\n",
       " 'jt': 0.9,\n",
       " 'jw': 1.6,\n",
       " 'jealz': -1.2,\n",
       " 'k4y': 2.3,\n",
       " 'kfy': 2.3,\n",
       " 'kia': -3.2,\n",
       " 'kk': 1.5,\n",
       " 'kmuf': 2.2,\n",
       " 'l': 2.0,\n",
       " 'l&r': 2.2,\n",
       " 'laoj': 1.3,\n",
       " 'lmao': 2.9,\n",
       " 'lmbao': 1.8,\n",
       " 'lmfao': 2.5,\n",
       " 'lmso': 2.7,\n",
       " 'lol': 1.8,\n",
       " 'lolz': 2.7,\n",
       " 'lts': 1.6,\n",
       " 'ly': 2.6,\n",
       " 'ly4e': 2.7,\n",
       " 'lya': 3.3,\n",
       " 'lyb': 3.0,\n",
       " 'lyl': 3.1,\n",
       " 'lylab': 2.7,\n",
       " 'lylas': 2.6,\n",
       " 'lylb': 1.6,\n",
       " 'm8': 1.4,\n",
       " 'mia': -1.2,\n",
       " 'mml': 2.0,\n",
       " 'mofo': -2.4,\n",
       " 'muah': 2.3,\n",
       " 'mubar': -1.0,\n",
       " 'musm': 0.9,\n",
       " 'mwah': 2.5,\n",
       " 'n1': 1.9,\n",
       " 'nbd': 1.3,\n",
       " 'nbif': -0.5,\n",
       " 'nfc': -2.7,\n",
       " 'nfw': -2.4,\n",
       " 'nh': 2.2,\n",
       " 'nimby': -0.8,\n",
       " 'nimjd': -0.7,\n",
       " 'nimq': -0.2,\n",
       " 'nimy': -1.4,\n",
       " 'nitl': -1.5,\n",
       " 'nme': -2.1,\n",
       " 'noyb': -0.7,\n",
       " 'np': 1.4,\n",
       " 'ntmu': 1.4,\n",
       " 'o-8': -0.5,\n",
       " 'o-:': -0.3,\n",
       " 'o-|': -1.1,\n",
       " 'o.o': -0.8,\n",
       " 'O.o': -0.6,\n",
       " 'o.O': -0.6,\n",
       " 'o:': -0.2,\n",
       " 'o:)': 1.5,\n",
       " 'o:-)': 2.0,\n",
       " 'o:-3': 2.2,\n",
       " 'o:3': 2.3,\n",
       " 'o:<': -0.3,\n",
       " 'o;^)': 1.6,\n",
       " 'ok': 1.2,\n",
       " 'o_o': -0.5,\n",
       " 'O_o': -0.5,\n",
       " 'o_O': -0.5,\n",
       " 'pita': -2.4,\n",
       " 'pls': 0.3,\n",
       " 'plz': 0.3,\n",
       " 'pmbi': 0.8,\n",
       " 'pmfji': 0.3,\n",
       " 'pmji': 0.7,\n",
       " 'po': -2.6,\n",
       " 'ptl': 2.6,\n",
       " 'pu': -1.1,\n",
       " 'qq': -2.2,\n",
       " 'qt': 1.8,\n",
       " 'r&r': 2.4,\n",
       " 'rofl': 2.7,\n",
       " 'roflmao': 2.5,\n",
       " 'rotfl': 2.6,\n",
       " 'rotflmao': 2.8,\n",
       " 'rotflmfao': 2.5,\n",
       " 'rotflol': 3.0,\n",
       " 'rotgl': 2.9,\n",
       " 'rotglmao': 1.8,\n",
       " 's:': -1.1,\n",
       " 'sapfu': -1.1,\n",
       " 'sete': 2.8,\n",
       " 'sfete': 2.7,\n",
       " 'sgtm': 2.4,\n",
       " 'slap': 0.6,\n",
       " 'slaw': 2.1,\n",
       " 'smh': -1.3,\n",
       " 'snafu': -2.5,\n",
       " 'sob': -1.0,\n",
       " 'swak': 2.3,\n",
       " 'tgif': 2.3,\n",
       " 'thks': 1.4,\n",
       " 'thx': 1.5,\n",
       " 'tia': 2.3,\n",
       " 'tmi': -0.3,\n",
       " 'tnx': 1.1,\n",
       " 'true': 1.8,\n",
       " 'tx': 1.5,\n",
       " 'txs': 1.1,\n",
       " 'ty': 1.6,\n",
       " 'tyvm': 2.5,\n",
       " 'urw': 1.9,\n",
       " 'vbg': 2.1,\n",
       " 'vbs': 3.1,\n",
       " 'vip': 2.3,\n",
       " 'vwd': 2.6,\n",
       " 'vwp': 2.1,\n",
       " 'wag': -0.2,\n",
       " 'wd': 2.7,\n",
       " 'wilco': 0.9,\n",
       " 'wp': 1.0,\n",
       " 'wtf': -2.8,\n",
       " 'wtg': 2.1,\n",
       " 'wth': -2.4,\n",
       " 'x-d': 2.6,\n",
       " 'x-p': 1.7,\n",
       " 'xd': 2.8,\n",
       " 'xlnt': 3.0,\n",
       " 'xoxo': 3.0,\n",
       " 'xoxozzz': 2.3,\n",
       " 'xp': 1.6,\n",
       " 'xqzt': 1.6,\n",
       " 'xtc': 0.8,\n",
       " 'yolo': 1.1,\n",
       " 'yoyo': 0.4,\n",
       " 'yvw': 1.6,\n",
       " 'yw': 1.8,\n",
       " 'ywia': 2.5,\n",
       " 'zzz': -1.2,\n",
       " '[-;': 0.5,\n",
       " '[:': 1.3,\n",
       " '[;': 1.0,\n",
       " '[=': 1.7,\n",
       " '\\\\-:': -1.0,\n",
       " '\\\\:': -1.0,\n",
       " '\\\\:<': -1.7,\n",
       " '\\\\=': -1.1,\n",
       " '\\\\^:': -1.3,\n",
       " '\\\\o/': 2.2,\n",
       " '\\\\o:': -1.2,\n",
       " ']-:': -2.1,\n",
       " ']:': -1.6,\n",
       " ']:<': -2.5,\n",
       " '^<_<': 1.4,\n",
       " '^urs': -2.8,\n",
       " 'abandon': -1.9,\n",
       " 'abandoned': -2.0,\n",
       " 'abandoner': -1.9,\n",
       " 'abandoners': -1.9,\n",
       " 'abandoning': -1.6,\n",
       " 'abandonment': -2.4,\n",
       " 'abandonments': -1.7,\n",
       " 'abandons': -1.3,\n",
       " 'abducted': -2.3,\n",
       " 'abduction': -2.8,\n",
       " 'abductions': -2.0,\n",
       " 'abhor': -2.0,\n",
       " 'abhorred': -2.4,\n",
       " 'abhorrent': -3.1,\n",
       " 'abhors': -2.9,\n",
       " 'abilities': 1.0,\n",
       " 'ability': 1.3,\n",
       " 'aboard': 0.1,\n",
       " 'absentee': -1.1,\n",
       " 'absentees': -0.8,\n",
       " 'absolve': 1.2,\n",
       " 'absolved': 1.5,\n",
       " 'absolves': 1.3,\n",
       " 'absolving': 1.6,\n",
       " 'abuse': -3.2,\n",
       " 'abused': -2.3,\n",
       " 'abuser': -2.6,\n",
       " 'abusers': -2.6,\n",
       " 'abuses': -2.6,\n",
       " 'abusing': -2.0,\n",
       " 'abusive': -3.2,\n",
       " 'abusively': -2.8,\n",
       " 'abusiveness': -2.5,\n",
       " 'abusivenesses': -3.0,\n",
       " 'accept': 1.6,\n",
       " 'acceptabilities': 1.6,\n",
       " 'acceptability': 1.1,\n",
       " 'acceptable': 1.3,\n",
       " 'acceptableness': 1.3,\n",
       " 'acceptably': 1.5,\n",
       " 'acceptance': 2.0,\n",
       " 'acceptances': 1.7,\n",
       " 'acceptant': 1.6,\n",
       " 'acceptation': 1.3,\n",
       " 'acceptations': 0.9,\n",
       " 'accepted': 1.1,\n",
       " 'accepting': 1.6,\n",
       " 'accepts': 1.3,\n",
       " 'accident': -2.1,\n",
       " 'accidental': -0.3,\n",
       " 'accidentally': -1.4,\n",
       " 'accidents': -1.3,\n",
       " 'accomplish': 1.8,\n",
       " 'accomplished': 1.9,\n",
       " 'accomplishes': 1.7,\n",
       " 'accusation': -1.0,\n",
       " 'accusations': -1.3,\n",
       " 'accuse': -0.8,\n",
       " 'accused': -1.2,\n",
       " 'accuses': -1.4,\n",
       " 'accusing': -0.7,\n",
       " 'ache': -1.6,\n",
       " 'ached': -1.6,\n",
       " 'aches': -1.0,\n",
       " 'achievable': 1.3,\n",
       " 'aching': -2.2,\n",
       " 'acquit': 0.8,\n",
       " 'acquits': 0.1,\n",
       " 'acquitted': 1.0,\n",
       " 'acquitting': 1.3,\n",
       " 'acrimonious': -1.7,\n",
       " 'active': 1.7,\n",
       " 'actively': 1.3,\n",
       " 'activeness': 0.6,\n",
       " 'activenesses': 0.8,\n",
       " 'actives': 1.1,\n",
       " 'adequate': 0.9,\n",
       " 'admirability': 2.4,\n",
       " 'admirable': 2.6,\n",
       " 'admirableness': 2.2,\n",
       " 'admirably': 2.5,\n",
       " 'admiral': 1.3,\n",
       " 'admirals': 1.5,\n",
       " 'admiralties': 1.6,\n",
       " 'admiralty': 1.2,\n",
       " 'admiration': 2.5,\n",
       " 'admirations': 1.6,\n",
       " 'admire': 2.1,\n",
       " 'admired': 2.3,\n",
       " 'admirer': 1.8,\n",
       " 'admirers': 1.7,\n",
       " 'admires': 1.5,\n",
       " 'admiring': 1.6,\n",
       " 'admiringly': 2.3,\n",
       " 'admit': 0.8,\n",
       " 'admits': 1.2,\n",
       " 'admitted': 0.4,\n",
       " 'admonished': -1.9,\n",
       " 'adopt': 0.7,\n",
       " 'adopts': 0.7,\n",
       " 'adorability': 2.2,\n",
       " 'adorable': 2.2,\n",
       " 'adorableness': 2.5,\n",
       " 'adorably': 2.1,\n",
       " 'adoration': 2.9,\n",
       " 'adorations': 2.2,\n",
       " 'adore': 2.6,\n",
       " 'adored': 1.8,\n",
       " 'adorer': 1.7,\n",
       " 'adorers': 2.1,\n",
       " 'adores': 1.6,\n",
       " 'adoring': 2.6,\n",
       " 'adoringly': 2.4,\n",
       " 'adorn': 0.9,\n",
       " 'adorned': 0.8,\n",
       " 'adorner': 1.3,\n",
       " 'adorners': 0.9,\n",
       " 'adorning': 1.0,\n",
       " 'adornment': 1.3,\n",
       " 'adornments': 0.8,\n",
       " 'adorns': 0.5,\n",
       " 'advanced': 1.0,\n",
       " 'advantage': 1.0,\n",
       " 'advantaged': 1.4,\n",
       " 'advantageous': 1.5,\n",
       " 'advantageously': 1.9,\n",
       " 'advantageousness': 1.6,\n",
       " 'advantages': 1.5,\n",
       " 'advantaging': 1.6,\n",
       " 'adventure': 1.3,\n",
       " 'adventured': 1.3,\n",
       " 'adventurer': 1.2,\n",
       " 'adventurers': 0.9,\n",
       " 'adventures': 1.4,\n",
       " 'adventuresome': 1.7,\n",
       " 'adventuresomeness': 1.3,\n",
       " 'adventuress': 0.8,\n",
       " 'adventuresses': 1.4,\n",
       " 'adventuring': 2.3,\n",
       " 'adventurism': 1.5,\n",
       " 'adventurist': 1.4,\n",
       " 'adventuristic': 1.7,\n",
       " 'adventurists': 1.2,\n",
       " 'adventurous': 1.4,\n",
       " 'adventurously': 1.3,\n",
       " 'adventurousness': 1.8,\n",
       " 'adversarial': -1.5,\n",
       " 'adversaries': -1.0,\n",
       " 'adversary': -0.8,\n",
       " 'adversative': -1.2,\n",
       " 'adversatively': -0.1,\n",
       " 'adversatives': -1.0,\n",
       " 'adverse': -1.5,\n",
       " 'adversely': -0.8,\n",
       " 'adverseness': -0.6,\n",
       " 'adversities': -1.5,\n",
       " 'adversity': -1.8,\n",
       " 'affected': -0.6,\n",
       " 'affection': 2.4,\n",
       " 'affectional': 1.9,\n",
       " 'affectionally': 1.5,\n",
       " 'affectionate': 1.9,\n",
       " 'affectionately': 2.2,\n",
       " 'affectioned': 1.8,\n",
       " 'affectionless': -2.0,\n",
       " 'affections': 1.5,\n",
       " 'afflicted': -1.5,\n",
       " 'affronted': 0.2,\n",
       " 'aggravate': -2.5,\n",
       " 'aggravated': -1.9,\n",
       " 'aggravates': -1.9,\n",
       " 'aggravating': -1.2,\n",
       " 'aggress': -1.3,\n",
       " 'aggressed': -1.4,\n",
       " 'aggresses': -0.5,\n",
       " 'aggressing': -0.6,\n",
       " 'aggression': -1.2,\n",
       " 'aggressions': -1.3,\n",
       " 'aggressive': -0.6,\n",
       " 'aggressively': -1.3,\n",
       " 'aggressiveness': -1.8,\n",
       " 'aggressivities': -1.4,\n",
       " 'aggressivity': -0.6,\n",
       " 'aggressor': -0.8,\n",
       " 'aggressors': -0.9,\n",
       " 'aghast': -1.9,\n",
       " 'agitate': -1.7,\n",
       " 'agitated': -2.0,\n",
       " 'agitatedly': -1.6,\n",
       " 'agitates': -1.4,\n",
       " 'agitating': -1.8,\n",
       " 'agitation': -1.0,\n",
       " 'agitational': -1.2,\n",
       " 'agitations': -1.3,\n",
       " 'agitative': -1.3,\n",
       " 'agitato': -0.1,\n",
       " 'agitator': -1.4,\n",
       " 'agitators': -2.1,\n",
       " 'agog': 1.9,\n",
       " 'agonise': -2.1,\n",
       " 'agonised': -2.3,\n",
       " 'agonises': -2.4,\n",
       " 'agonising': -1.5,\n",
       " 'agonize': -2.3,\n",
       " 'agonized': -2.2,\n",
       " 'agonizes': -2.3,\n",
       " 'agonizing': -2.7,\n",
       " 'agonizingly': -2.3,\n",
       " 'agony': -1.8,\n",
       " 'agree': 1.5,\n",
       " 'agreeability': 1.9,\n",
       " 'agreeable': 1.8,\n",
       " 'agreeableness': 1.8,\n",
       " 'agreeablenesses': 1.3,\n",
       " 'agreeably': 1.6,\n",
       " 'agreed': 1.1,\n",
       " 'agreeing': 1.4,\n",
       " 'agreement': 2.2,\n",
       " 'agreements': 1.1,\n",
       " 'agrees': 0.8,\n",
       " 'alarm': -1.4,\n",
       " 'alarmed': -1.4,\n",
       " 'alarming': -0.5,\n",
       " 'alarmingly': -2.6,\n",
       " 'alarmism': -0.3,\n",
       " 'alarmists': -1.1,\n",
       " 'alarms': -1.1,\n",
       " 'alas': -1.1,\n",
       " 'alert': 1.2,\n",
       " 'alienation': -1.1,\n",
       " 'alive': 1.6,\n",
       " 'allergic': -1.2,\n",
       " 'allow': 0.9,\n",
       " 'alone': -1.0,\n",
       " 'alright': 1.0,\n",
       " 'amaze': 2.5,\n",
       " 'amazed': 2.2,\n",
       " 'amazedly': 2.1,\n",
       " 'amazement': 2.5,\n",
       " 'amazements': 2.2,\n",
       " 'amazes': 2.2,\n",
       " 'amazing': 2.8,\n",
       " 'amazon': 0.7,\n",
       " 'amazonite': 0.2,\n",
       " 'amazons': -0.1,\n",
       " 'amazonstone': 1.0,\n",
       " 'amazonstones': 0.2,\n",
       " 'ambitious': 2.1,\n",
       " 'ambivalent': 0.5,\n",
       " 'amor': 3.0,\n",
       " 'amoral': -1.6,\n",
       " 'amoralism': -0.7,\n",
       " 'amoralisms': -0.7,\n",
       " 'amoralities': -1.2,\n",
       " 'amorality': -1.5,\n",
       " 'amorally': -1.0,\n",
       " 'amoretti': 0.2,\n",
       " 'amoretto': 0.6,\n",
       " 'amorettos': 0.3,\n",
       " 'amorino': 1.2,\n",
       " 'amorist': 1.6,\n",
       " 'amoristic': 1.0,\n",
       " 'amorists': 0.1,\n",
       " 'amoroso': 2.3,\n",
       " 'amorous': 1.8,\n",
       " 'amorously': 2.3,\n",
       " 'amorousness': 2.0,\n",
       " 'amorphous': -0.2,\n",
       " 'amorphously': 0.1,\n",
       " 'amorphousness': 0.3,\n",
       " 'amort': -2.1,\n",
       " 'amortise': 0.5,\n",
       " 'amortised': -0.2,\n",
       " 'amortises': 0.1,\n",
       " 'amortizable': 0.5,\n",
       " 'amortization': 0.6,\n",
       " 'amortizations': 0.2,\n",
       " 'amortize': -0.1,\n",
       " 'amortized': 0.8,\n",
       " 'amortizes': 0.6,\n",
       " 'amortizing': 0.8,\n",
       " 'amusable': 0.7,\n",
       " 'amuse': 1.7,\n",
       " 'amused': 1.8,\n",
       " 'amusedly': 2.2,\n",
       " 'amusement': 1.5,\n",
       " 'amusements': 1.5,\n",
       " 'amuser': 1.1,\n",
       " 'amusers': 1.3,\n",
       " 'amuses': 1.7,\n",
       " 'amusia': 0.3,\n",
       " 'amusias': -0.4,\n",
       " 'amusing': 1.6,\n",
       " 'amusingly': 0.8,\n",
       " 'amusingness': 1.8,\n",
       " 'amusive': 1.7,\n",
       " 'anger': -2.7,\n",
       " 'angered': -2.3,\n",
       " 'angering': -2.2,\n",
       " 'angerly': -1.9,\n",
       " 'angers': -2.3,\n",
       " 'angrier': -2.3,\n",
       " 'angriest': -3.1,\n",
       " 'angrily': -1.8,\n",
       " 'angriness': -1.7,\n",
       " 'angry': -2.3,\n",
       " 'anguish': -2.9,\n",
       " 'anguished': -1.8,\n",
       " 'anguishes': -2.1,\n",
       " 'anguishing': -2.7,\n",
       " 'animosity': -1.9,\n",
       " 'annoy': -1.9,\n",
       " 'annoyance': -1.3,\n",
       " 'annoyances': -1.8,\n",
       " 'annoyed': -1.6,\n",
       " 'annoyer': -2.2,\n",
       " 'annoyers': -1.5,\n",
       " 'annoying': -1.7,\n",
       " 'annoys': -1.8,\n",
       " 'antagonism': -1.9,\n",
       " 'antagonisms': -1.2,\n",
       " 'antagonist': -1.9,\n",
       " 'antagonistic': -1.7,\n",
       " 'antagonistically': -2.2,\n",
       " 'antagonists': -1.7,\n",
       " 'antagonize': -2.0,\n",
       " 'antagonized': -1.4,\n",
       " 'antagonizes': -0.5,\n",
       " 'antagonizing': -2.7,\n",
       " 'anti': -1.3,\n",
       " 'anticipation': 0.4,\n",
       " 'anxieties': -0.6,\n",
       " 'anxiety': -0.7,\n",
       " 'anxious': -1.0,\n",
       " 'anxiously': -0.9,\n",
       " 'anxiousness': -1.0,\n",
       " 'aok': 2.0,\n",
       " 'apathetic': -1.2,\n",
       " 'apathetically': -0.4,\n",
       " 'apathies': -0.6,\n",
       " 'apathy': -1.2,\n",
       " 'apeshit': -0.9,\n",
       " 'apocalyptic': -3.4,\n",
       " 'apologise': 1.6,\n",
       " 'apologised': 0.4,\n",
       " 'apologises': 0.8,\n",
       " 'apologising': 0.2,\n",
       " 'apologize': 0.4,\n",
       " 'apologized': 1.3,\n",
       " 'apologizes': 1.5,\n",
       " 'apologizing': -0.3,\n",
       " 'apology': 0.2,\n",
       " 'appall': -2.4,\n",
       " 'appalled': -2.0,\n",
       " 'appalling': -1.5,\n",
       " 'appallingly': -2.0,\n",
       " 'appalls': -1.9,\n",
       " 'appease': 1.1,\n",
       " 'appeased': 0.9,\n",
       " 'appeases': 0.9,\n",
       " 'appeasing': 1.0,\n",
       " 'applaud': 2.0,\n",
       " 'applauded': 1.5,\n",
       " 'applauding': 2.1,\n",
       " 'applauds': 1.4,\n",
       " 'applause': 1.8,\n",
       " 'appreciate': 1.7,\n",
       " 'appreciated': 2.3,\n",
       " 'appreciates': 2.3,\n",
       " 'appreciating': 1.9,\n",
       " 'appreciation': 2.3,\n",
       " 'appreciations': 1.7,\n",
       " 'appreciative': 2.6,\n",
       " 'appreciatively': 1.8,\n",
       " 'appreciativeness': 1.6,\n",
       " 'appreciator': 2.6,\n",
       " 'appreciators': 1.5,\n",
       " 'appreciatory': 1.7,\n",
       " 'apprehensible': 1.1,\n",
       " 'apprehensibly': -0.2,\n",
       " 'apprehension': -2.1,\n",
       " 'apprehensions': -0.9,\n",
       " 'apprehensively': -0.3,\n",
       " 'apprehensiveness': -0.7,\n",
       " 'approval': 2.1,\n",
       " 'approved': 1.8,\n",
       " 'approves': 1.7,\n",
       " 'ardent': 2.1,\n",
       " 'arguable': -1.0,\n",
       " 'arguably': -1.0,\n",
       " 'argue': -1.4,\n",
       " 'argued': -1.5,\n",
       " 'arguer': -1.6,\n",
       " 'arguers': -1.4,\n",
       " 'argues': -1.6,\n",
       " 'arguing': -2.0,\n",
       " 'argument': -1.5,\n",
       " 'argumentative': -1.5,\n",
       " 'argumentatively': -1.8,\n",
       " 'argumentive': -1.5,\n",
       " 'arguments': -1.7,\n",
       " 'arrest': -1.4,\n",
       " 'arrested': -2.1,\n",
       " 'arrests': -1.9,\n",
       " 'arrogance': -2.4,\n",
       " 'arrogances': -1.9,\n",
       " 'arrogant': -2.2,\n",
       " 'arrogantly': -1.8,\n",
       " 'ashamed': -2.1,\n",
       " 'ashamedly': -1.7,\n",
       " 'ass': -2.5,\n",
       " 'assassination': -2.9,\n",
       " 'assassinations': -2.7,\n",
       " 'assault': -2.8,\n",
       " 'assaulted': -2.4,\n",
       " 'assaulting': -2.3,\n",
       " 'assaultive': -2.8,\n",
       " 'assaults': -2.5,\n",
       " 'asset': 1.5,\n",
       " 'assets': 0.7,\n",
       " 'assfucking': -2.5,\n",
       " 'assholes': -2.8,\n",
       " 'assurance': 1.4,\n",
       " 'assurances': 1.4,\n",
       " 'assure': 1.4,\n",
       " 'assured': 1.5,\n",
       " 'assuredly': 1.6,\n",
       " 'assuredness': 1.4,\n",
       " 'assurer': 0.9,\n",
       " 'assurers': 1.1,\n",
       " 'assures': 1.3,\n",
       " 'assurgent': 1.3,\n",
       " 'assuring': 1.6,\n",
       " 'assuror': 0.5,\n",
       " 'assurors': 0.7,\n",
       " 'astonished': 1.6,\n",
       " 'astound': 1.7,\n",
       " 'astounded': 1.8,\n",
       " 'astounding': 1.8,\n",
       " 'astoundingly': 2.1,\n",
       " 'astounds': 2.1,\n",
       " 'attachment': 1.2,\n",
       " 'attachments': 1.1,\n",
       " 'attack': -2.1,\n",
       " 'attacked': -2.0,\n",
       " 'attacker': -2.7,\n",
       " 'attackers': -2.7,\n",
       " 'attacking': -2.0,\n",
       " 'attacks': -1.9,\n",
       " 'attract': 1.5,\n",
       " 'attractancy': 0.9,\n",
       " 'attractant': 1.3,\n",
       " 'attractants': 1.4,\n",
       " 'attracted': 1.8,\n",
       " 'attracting': 2.1,\n",
       " 'attraction': 2.0,\n",
       " 'attractions': 1.8,\n",
       " 'attractive': 1.9,\n",
       " 'attractively': 2.2,\n",
       " 'attractiveness': 1.8,\n",
       " 'attractivenesses': 2.1,\n",
       " 'attractor': 1.2,\n",
       " 'attractors': 1.2,\n",
       " 'attracts': 1.7,\n",
       " 'audacious': 0.9,\n",
       " 'authority': 0.3,\n",
       " 'aversion': -1.9,\n",
       " 'aversions': -1.1,\n",
       " 'aversive': -1.6,\n",
       " 'aversively': -0.8,\n",
       " 'avert': -0.7,\n",
       " 'averted': -0.3,\n",
       " 'averts': -0.4,\n",
       " 'avid': 1.2,\n",
       " 'avoid': -1.2,\n",
       " 'avoidance': -1.7,\n",
       " 'avoidances': -1.1,\n",
       " 'avoided': -1.4,\n",
       " 'avoider': -1.8,\n",
       " 'avoiders': -1.4,\n",
       " 'avoiding': -1.4,\n",
       " 'avoids': -0.7,\n",
       " 'await': 0.4,\n",
       " 'awaited': -0.1,\n",
       " 'awaits': 0.3,\n",
       " 'award': 2.5,\n",
       " 'awardable': 2.4,\n",
       " 'awarded': 1.7,\n",
       " 'awardee': 1.8,\n",
       " 'awardees': 1.2,\n",
       " 'awarder': 0.9,\n",
       " 'awarders': 1.3,\n",
       " 'awarding': 1.9,\n",
       " 'awards': 2.0,\n",
       " 'awesome': 3.1,\n",
       " 'awful': -2.0,\n",
       " 'awkward': -0.6,\n",
       " 'awkwardly': -1.3,\n",
       " 'awkwardness': -0.7,\n",
       " 'axe': -0.4,\n",
       " 'axed': -1.3,\n",
       " 'backed': 0.1,\n",
       " 'backing': 0.1,\n",
       " 'backs': -0.2,\n",
       " 'bad': -2.5,\n",
       " 'badass': -0.6,\n",
       " 'badly': -2.1,\n",
       " 'bailout': -0.4,\n",
       " 'bamboozle': -1.5,\n",
       " 'bamboozled': -1.5,\n",
       " 'bamboozles': -1.5,\n",
       " 'ban': -2.6,\n",
       " 'banish': -1.9,\n",
       " 'bankrupt': -2.6,\n",
       " 'bankster': -2.1,\n",
       " 'banned': -2.0,\n",
       " 'bargain': 0.8,\n",
       " 'barrier': -0.5,\n",
       " 'bashful': -0.1,\n",
       " 'bashfully': 0.2,\n",
       " 'bashfulness': -0.8,\n",
       " 'bastard': -2.5,\n",
       " 'bastardies': -1.8,\n",
       " 'bastardise': -2.1,\n",
       " 'bastardised': -2.3,\n",
       " 'bastardises': -2.3,\n",
       " 'bastardising': -2.6,\n",
       " 'bastardization': -2.4,\n",
       " 'bastardizations': -2.1,\n",
       " 'bastardize': -2.4,\n",
       " 'bastardized': -2.0,\n",
       " 'bastardizes': -1.8,\n",
       " 'bastardizing': -2.3,\n",
       " 'bastardly': -2.7,\n",
       " 'bastards': -3.0,\n",
       " 'bastardy': -2.7,\n",
       " 'battle': -1.6,\n",
       " 'battled': -1.2,\n",
       " 'battlefield': -1.6,\n",
       " 'battlefields': -0.9,\n",
       " 'battlefront': -1.2,\n",
       " 'battlefronts': -0.8,\n",
       " 'battleground': -1.7,\n",
       " 'battlegrounds': -0.6,\n",
       " 'battlement': -0.4,\n",
       " 'battlements': -0.4,\n",
       " 'battler': -0.8,\n",
       " 'battlers': -0.2,\n",
       " 'battles': -1.6,\n",
       " 'battleship': -0.1,\n",
       " 'battleships': -0.5,\n",
       " 'battlewagon': -0.3,\n",
       " 'battlewagons': -0.5,\n",
       " 'battling': -1.1,\n",
       " 'beaten': -1.8,\n",
       " 'beatific': 1.8,\n",
       " 'beating': -2.0,\n",
       " 'beaut': 1.6,\n",
       " 'beauteous': 2.5,\n",
       " 'beauteously': 2.6,\n",
       " 'beauteousness': 2.7,\n",
       " 'beautician': 1.2,\n",
       " 'beauticians': 0.4,\n",
       " ...}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3c9082b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"4e75113b06eb4a6792123a54c38d8124-0\" class=\"displacy\" width=\"1625\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">do</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">not</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">think</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">hotel</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">staff</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">was</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">friendly</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4e75113b06eb4a6792123a54c38d8124-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,89.5 570.0,89.5 570.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4e75113b06eb4a6792123a54c38d8124-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4e75113b06eb4a6792123a54c38d8124-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,177.0 565.0,177.0 565.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4e75113b06eb4a6792123a54c38d8124-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4e75113b06eb4a6792123a54c38d8124-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,264.5 560.0,264.5 560.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4e75113b06eb4a6792123a54c38d8124-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">neg</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4e75113b06eb4a6792123a54c38d8124-0-3\" stroke-width=\"2px\" d=\"M770,352.0 C770,177.0 1090.0,177.0 1090.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4e75113b06eb4a6792123a54c38d8124-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,354.0 L762,342.0 778,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4e75113b06eb4a6792123a54c38d8124-0-4\" stroke-width=\"2px\" d=\"M945,352.0 C945,264.5 1085.0,264.5 1085.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4e75113b06eb4a6792123a54c38d8124-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,354.0 L937,342.0 953,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4e75113b06eb4a6792123a54c38d8124-0-5\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,264.5 1260.0,264.5 1260.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4e75113b06eb4a6792123a54c38d8124-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,354.0 L1112,342.0 1128,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4e75113b06eb4a6792123a54c38d8124-0-6\" stroke-width=\"2px\" d=\"M595,352.0 C595,2.0 1275.0,2.0 1275.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4e75113b06eb4a6792123a54c38d8124-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1275.0,354.0 L1283.0,342.0 1267.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4e75113b06eb4a6792123a54c38d8124-0-7\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,264.5 1435.0,264.5 1435.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4e75113b06eb4a6792123a54c38d8124-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1435.0,354.0 L1443.0,342.0 1427.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "doc = nlp(\"I do not think the hotel staff was friendly\")\n",
    "displacy.render(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6a032c",
   "metadata": {},
   "source": [
    "### Task 3.2\n",
    "\n",
    "Considering modifiers to adjust the polarity values of the aspect opinions in Assignment 4. The modifiers to use could be those provided with the NLTK Sentiment Analyzer (see Appendix G) and/or those given in modifiers.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "997b4f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modifier</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>above</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>absolutely</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abundantly</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acutely</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amazingly</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>violently</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>whimsically</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>wickedly</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>wretchedly</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>wrongly</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        modifier  value\n",
       "0          above    2.0\n",
       "1     absolutely    2.0\n",
       "2     abundantly    2.0\n",
       "3        acutely    2.0\n",
       "4      amazingly    2.0\n",
       "..           ...    ...\n",
       "295    violently   -1.0\n",
       "296  whimsically   -1.0\n",
       "297     wickedly   -1.0\n",
       "298   wretchedly   -1.0\n",
       "299      wrongly   -1.0\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modifiers = pd.read_csv(\"modifiers/modifiers.csv\", header = None, names=['modifier', 'value'] )\n",
    "modifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "152a997d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'absolutely': 0.293, 'amazingly': 0.293, 'awfully': 0.293, 'completely': 0.293, 'considerably': 0.293, 'decidedly': 0.293, 'deeply': 0.293, 'effing': 0.293, 'enormously': 0.293, 'entirely': 0.293, 'especially': 0.293, 'exceptionally': 0.293, 'extremely': 0.293, 'fabulously': 0.293, 'flipping': 0.293, 'flippin': 0.293, 'fricking': 0.293, 'frickin': 0.293, 'frigging': 0.293, 'friggin': 0.293, 'fully': 0.293, 'fucking': 0.293, 'greatly': 0.293, 'hella': 0.293, 'highly': 0.293, 'hugely': 0.293, 'incredibly': 0.293, 'intensely': 0.293, 'majorly': 0.293, 'more': 0.293, 'most': 0.293, 'particularly': 0.293, 'purely': 0.293, 'quite': 0.293, 'really': 0.293, 'remarkably': 0.293, 'so': 0.293, 'substantially': 0.293, 'thoroughly': 0.293, 'totally': 0.293, 'tremendously': 0.293, 'uber': 0.293, 'unbelievably': 0.293, 'unusually': 0.293, 'utterly': 0.293, 'very': 0.293, 'almost': -0.293, 'barely': -0.293, 'hardly': -0.293, 'just enough': -0.293, 'kind of': -0.293, 'kinda': -0.293, 'kindof': -0.293, 'kind-of': -0.293, 'less': -0.293, 'little': -0.293, 'marginally': -0.293, 'occasionally': -0.293, 'partly': -0.293, 'scarcely': -0.293, 'slightly': -0.293, 'somewhat': -0.293, 'sort of': -0.293, 'sorta': -0.293, 'sortof': -0.293, 'sort-of': -0.293}\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.vader import VaderConstants\n",
    "\n",
    "constants = VaderConstants()\n",
    "print(constants.BOOSTER_DICT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b79b65",
   "metadata": {},
   "source": [
    "## Assignment 4: Aspect opinions\n",
    "\n",
    "Once the aspect vocabulary and opinion lexicons are loaded, the opinions about aspects have to be extracted\n",
    "from the reviews. For this purpose, POS tagging, constituency and dependency parsing could be used.\n",
    "- POS tagging would allow identifying the adjectives in the sentences.\n",
    "- Constituency and dependency parsing would allow extracting the relations between nouns and adjectives and adverbs.\n",
    "\n",
    "#### Task 4.1 -: \n",
    "Extracting the [aspect, aspect term, opinion word, polarity] tuples from the input reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f7766542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# IMPORTANT FUNCTIONS\n",
    "\n",
    "\n",
    "# Define a function to clean the text\n",
    "def clean(text):\n",
    "    # Removes all special characters and numericals leaving the alphabets\n",
    "    text = re.sub(r\"[()\\\"#/@;:<>{}`+=~|!?,]\", \"\", text)\n",
    "    text = re.sub(r\"[.]\", \". \", text)\n",
    "    return text\n",
    "    \n",
    "\n",
    "def get_aspect(word, aspects):\n",
    "    if word in aspects: return word\n",
    "    \n",
    "    for key in aspects:\n",
    "        if word in aspects[key]: return key\n",
    "    return word\n",
    "\n",
    "def get_polarity(dict_inf):\n",
    "    sentence = dict_inf['adjetive'] +' '+ dict_inf['word']\n",
    "    polarity = get_vader_score(sentence)\n",
    "    if polarity == 0.0:\n",
    "        if get_sentiment(sentence) < 0.0: return -1.0\n",
    "        elif get_sentiment(sentence) > 0.0: return 1.0\n",
    "        else: return 0.0\n",
    "    return polarity\n",
    "\n",
    "# AUXILIAR FUNCTIONS\n",
    "\n",
    "def get_compound(dict_inf, item_type, word1, word2):\n",
    "    word_list =  dict_inf[item_type].split()\n",
    "    idx = word_list.index(word1)\n",
    "    new_split = [word2]\n",
    "    new_split += word_list[idx:]\n",
    "    dict_inf[item_type] = ' '.join(word_list[:idx] + new_split)\n",
    "    return dict_inf\n",
    "\n",
    "def save_information(aspect, dict_inf, data):\n",
    "    if aspect != None and 'adjetive' in dict_inf:       \n",
    "        dict_inf['aspect'] = aspect.upper()\n",
    "        dict_inf['polarity'] = get_polarity(dict_inf)\n",
    "        data = data.append(dict_inf, ignore_index=True)\n",
    "        dict_inf = {}\n",
    "\n",
    "    return data, dict_inf\n",
    "\n",
    "\n",
    "# MAIN CODE RULES\n",
    "\n",
    "def get_information(head, relation, dependent,  aspect, dict_inf, data):\n",
    "    word1, pos1 = head\n",
    "    word2, pos2 = dependent\n",
    "    \n",
    "    word1 = word1.lower()\n",
    "    word2 = word2.lower()\n",
    "    \n",
    "    if relation == 'amod' and pos1.startswith('NN') and pos2.startswith('JJ'):\n",
    "        if 'adjetive' in dict_inf and word1 not in dict_inf['word']:\n",
    "            data, dict_inf = save_information(aspect, dict_inf, data)\n",
    "            \n",
    "        aspect = get_aspect(word1, aspects_hotels)\n",
    "        if 'adjetive' in dict_inf: dict_inf['adjetive'] += ' ' + word2\n",
    "        else: dict_inf['adjetive'] = word2\n",
    "        if 'word' not in dict_inf: dict_inf['word'] = word1\n",
    "            \n",
    "    elif relation == 'det' and pos1.startswith('NN') and pos2.startswith('DT') and word2 == 'no':\n",
    "        dict_inf['word'] = word1\n",
    "        dict_inf['adjetive'] = 'not'\n",
    "            \n",
    "    elif relation == 'conj' and pos1.startswith('JJ') and pos2.startswith('NN'):\n",
    "        if 'adjetive' in dict_inf and word1 in dict_inf['adjetive']:\n",
    "            dict_inf['adjetive'] += ' ' + word2\n",
    "\n",
    "    elif relation == 'conj' and pos1.startswith('NN') and pos2.startswith('NN'):\n",
    "        if 'word' in dict_inf and word1 in dict_inf['word']:\n",
    "            dict_inf['word'] += ' ' + word2\n",
    "\n",
    "    elif relation == 'dep' and pos1.startswith('NN') and pos2.startswith('NN'):\n",
    "        if 'word' in dict_inf and word1 in dict_inf['word']:\n",
    "            dict_inf['word'] += ' ' + word2\n",
    "    \n",
    "    elif relation == 'amod' and pos1.startswith('NN') and pos2.startswith('VBN'):\n",
    "        if 'word' in dict_inf and word1 in dict_inf['word']:\n",
    "            dict_inf = get_compound(dict_inf, 'word', word1, word2)\n",
    "    \n",
    "    elif relation == 'acl' and pos1.startswith('NN') and pos2.startswith('VB'):\n",
    "        if 'word' in dict_inf and word1 in dict_inf['word']: dict_inf['word'] = word1 + ' ' + word2\n",
    "    \n",
    "    elif relation == 'mark' and pos1.startswith('VB') and pos2.startswith('TO'):\n",
    "        if 'word' in dict_inf and word1 in dict_inf['word']:\n",
    "            dict_inf = get_compound(dict_inf, 'word', word1, word2)\n",
    "            \n",
    "    elif relation == 'nsubj' and pos1.startswith('JJ') and pos2.startswith('PRP') and word2 == 'it':        \n",
    "        adjetive = data['adjetive'].iloc[len(data)-1]\n",
    "        adjetive = re.sub(r\"[-]\", \" \", adjetive)\n",
    "        if word1 in negativeWords:\n",
    "            if 'none' in adjetive: adjetive = ' '.join(adjetive.split('none'))\n",
    "            elif 'not' in adjetive: adjetive = ' '.join(adjetive.split('not'))\n",
    "            elif 'non' in adjetive: adjetive = ' '.join(adjetive.split('non'))\n",
    "                \n",
    "        dict_inf['adjetive'] = word1 + ' ' + adjetive\n",
    "        dict_inf['word'] = data['word'].iloc[len(data)-1]\n",
    "        data.at[len(data)-1,'adjetive'] = dict_inf['adjetive']\n",
    "        data.at[len(data)-1,'polarity'] = get_polarity(dict_inf)\n",
    "\n",
    "        \n",
    "    elif relation == 'nsubj' and pos1.startswith('JJ') and pos2.startswith('NN'):\n",
    "        if pos2 != 'NNP':\n",
    "            data, dict_inf = save_information(aspect, dict_inf, data)\n",
    "            aspect = get_aspect(word2, aspects_hotels)\n",
    "\n",
    "        dict_inf['adjetive'] = word1\n",
    "        dict_inf['word'] = word2\n",
    "    \n",
    "    elif relation == 'nummod' and pos1.startswith('NN') and pos2.startswith('CD'):\n",
    "        if 'word' in dict_inf and word1 in dict_inf['word']:\n",
    "            dict_inf = get_compound(dict_inf, 'word', word1, word2)\n",
    "    \n",
    "    elif relation == 'compound' and pos1.startswith('NN') and pos2.startswith('NN'):\n",
    "        if 'word' in dict_inf and word1 in dict_inf['word']:\n",
    "            dict_inf = get_compound(dict_inf, 'word', word1, word2)\n",
    "            if aspect == None: aspect = get_aspect(word2, aspects_hotels)\n",
    "    \n",
    "    elif relation == 'advmod' and pos1.startswith('JJ') and pos2.startswith('RB'):\n",
    "        if 'adjetive' in dict_inf and word1 in dict_inf['adjetive']:\n",
    "            dict_inf = get_compound(dict_inf, 'adjetive', word1, word2)\n",
    "    \n",
    "    elif relation == 'fixed' and pos1.startswith('RB') and pos2.startswith('RB'):\n",
    "        if 'adjetive' in dict_inf and word1 in dict_inf['adjetive']:\n",
    "            dict_inf = get_compound(dict_inf, 'adjetive', word1, word2)\n",
    "            \n",
    "    elif relation == 'obj' and pos1.startswith('VB') and pos2.startswith('NN'):\n",
    "        if 'word' in dict_inf and word1 in dict_inf['word']:\n",
    "            dict_inf['word'] += ' ' + word2\n",
    "    \n",
    "    elif relation == 'cc' and pos1.startswith('NN') and pos2.startswith('CC') and word2 != 'but':\n",
    "        if 'word' in dict_inf and word1 in dict_inf['word']:\n",
    "            dict_inf = get_compound(dict_inf, 'word', word1, word2)\n",
    "\n",
    "    \n",
    "    return aspect, dict_inf, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80269fde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ce9b47a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I feel the Days Inn Tempe is best described as a place where you can purchase the right to sleep for awhile.\n",
      "I booked my 10-night stay on Travelocity for a non-smoking room yet when I entered the room I almost choked.\n",
      "It was disgusting.\n",
      "I've never had a smoking hotel room before and I will make sure I don't again.\n",
      "They said they couldn't move us to a different room.\n",
      "My local lady friend brought over a bottle of wine but forgot a corkscrew.\n",
      "No big deal I thought to myself as the front desk of a hotel will surely have a corkscrew.\n",
      "Nope.\n",
      "Coors Light it is.\n",
      "The towels felt like they were made of cow tongue and they missed our wakeup call one morning making me late for a training class that had cost me about $500.\n",
      "I'm awarding one star in addition to the minimum one-star rating because I got to drink cheap beer by the pool in 90 degree weather for 10 days and there are a few good places to eat and two dollar stores very nearby.\n",
      "The dollar store had a corkscrew.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>aspect</th>\n",
       "      <th>adjetive</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>ROOM</td>\n",
       "      <td>disgusting   smoking</td>\n",
       "      <td>room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>ROOM</td>\n",
       "      <td>different</td>\n",
       "      <td>room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>LADY</td>\n",
       "      <td>local</td>\n",
       "      <td>lady</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>DEAL</td>\n",
       "      <td>not big</td>\n",
       "      <td>deal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>DESK</td>\n",
       "      <td>front</td>\n",
       "      <td>desk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>RATING</td>\n",
       "      <td>minimum</td>\n",
       "      <td>one star rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>DRINKS</td>\n",
       "      <td>cheap</td>\n",
       "      <td>beer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>PLACES</td>\n",
       "      <td>few good</td>\n",
       "      <td>places to eat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity  aspect              adjetive             word\n",
       "0      -1.0    ROOM  disgusting   smoking             room\n",
       "1       1.0    ROOM             different             room\n",
       "2       0.0    LADY                 local             lady\n",
       "3      -1.0    DEAL               not big             deal\n",
       "4       0.0    DESK                 front             desk\n",
       "5       0.0  RATING               minimum  one star rating\n",
       "6       0.0  DRINKS                 cheap             beer\n",
       "7       1.0  PLACES              few good    places to eat"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.parse.corenlp import CoreNLPDependencyParser\n",
    "\n",
    "data = pd.DataFrame(columns = ['polarity', 'aspect', 'adjetive', 'word'])\n",
    "\n",
    "dependency_parser = CoreNLPDependencyParser()\n",
    "\n",
    "review = reviews_hotels[1].get(\"reviewText\")\n",
    "review = clean(review)\n",
    "\n",
    "sentences = nltk.sent_tokenize(review)\n",
    "\n",
    "for s in sentences:\n",
    "    print(s)\n",
    "    result, = dependency_parser.raw_parse(s)\n",
    "    \n",
    "    dict_inf = {}\n",
    "    aspect = None\n",
    "    for head, relation, dependent in result.triples():\n",
    "        aspect, dict_inf, data = get_information(head, relation, dependent, aspect, dict_inf, data)\n",
    "    data, _ = save_information(aspect, dict_inf, data)\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "590158d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'packages'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_aspect('packages', aspects_hotels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0980311c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "sentence = 'disgusting smoking\troom'\n",
    "print(get_vader_score(sentence))\n",
    "print(get_sentiment(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1f52fadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>aspect</th>\n",
       "      <th>adjetive</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>ROOM</td>\n",
       "      <td>different</td>\n",
       "      <td>room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>DEAL</td>\n",
       "      <td>big</td>\n",
       "      <td>deal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>PLACES</td>\n",
       "      <td>few good</td>\n",
       "      <td>places to eat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity  aspect   adjetive           word\n",
       "1       1.0    ROOM  different           room\n",
       "3       1.0    DEAL        big           deal\n",
       "7       1.0  PLACES   few good  places to eat"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['polarity']!= 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "04a6a6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('hotel', 'NN') amod ('Great', 'JJ')\n",
      "('hotel', 'NN') nmod ('Phoenix', 'NNP')\n",
      "('Phoenix', 'NNP') case ('in', 'IN')\n",
      "('Phoenix', 'NNP') compound ('Central', 'NNP')\n",
      "('hotel', 'NN') nmod ('cation', 'NN')\n",
      "('cation', 'NN') case ('for', 'IN')\n",
      "('cation', 'NN') det ('a', 'DT')\n",
      "('cation', 'NN') compound ('stay', 'NN')\n",
      "('cation', 'NN') punct ('-', 'HYPH')\n",
      "('hotel', 'NN') conj ('place', 'NN')\n",
      "('place', 'NN') cc ('but', 'CC')\n",
      "('place', 'NN') advmod ('not', 'RB')\n",
      "('place', 'NN') advmod ('necessarily', 'RB')\n",
      "('place', 'NN') det ('a', 'DT')\n",
      "('place', 'NN') dep ('stay', 'VB')\n",
      "('stay', 'VB') mark ('to', 'TO')\n",
      "('stay', 'VB') obl ('town', 'NN')\n",
      "('town', 'NN') case ('out', 'IN')\n",
      "('town', 'NN') case ('of', 'IN')\n",
      "('stay', 'VB') conj ('car', 'NN')\n",
      "('car', 'NN') cc ('and', 'CC')\n",
      "('car', 'NN') case ('without', 'IN')\n",
      "('car', 'NN') det ('a', 'DT')\n",
      "('hotel', 'NN') punct ('.', '.')\n"
     ]
    }
   ],
   "source": [
    "# testing \n",
    "review = reviews_hotels[0].get(\"reviewText\")\n",
    "review = clean(review)\n",
    "sentences = nltk.sent_tokenize(review)\n",
    "    \n",
    "for s in [sentences[0]]:\n",
    "    result, = dependency_parser.raw_parse(s)\n",
    "    for head, relation, dependent in result.triples():\n",
    "        print(head, relation, dependent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d011d87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599deaaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
